---
title: >-
 Exploring the Ethical Challenges of Conversational AI in Mental Health Care
 Scoping Review
authors: Meadi et al.
year: 2025
source:
 - Journal
doi:
 - TBD
tags:
 - digital-divide
 - crisis-management
 - algorithmic-transparency
 - scoping-review
 - conversational-ai
 - ai-ethics
type: source
status: reviewed
added: 2024-12-13T00:00:00.000Z
relevance: high
---

# Meadi 2025 - Conversational AI Ethics Scoping Review
#lit #ai_ethics

Related: [[202512011220-AI Ethics & Mental Health Professionals]]


## Key Findings

**10 Ethical Themes Identified:**
1. **Safety & Harm** (52% of articles): suicidality/crisis management, harmful suggestions, dependency risk
2. **Justice** (41%): health inequalities, digital literacy gaps, access disparities
3. **Responsibility & Accountability** (31%): who is liable, unclear chains of responsibility
4. **Empathy & Humanness** (29%): can AI be empathic? human touch erosion
5. **Explicability, Transparency & Trust** (26%): "black box" algorithms undermine trust
6-10. [Additional themes from full text]

**Temporal:** 95% articles published 2018 or later - recent phenomenon
**Top Concern:** Suicidality & crisis management within safety/harm theme

## Methodology
**Design:** Scoping review
**Databases:** 7 databases (PubMed, Embase, PsycINFO, Web of Science, Scopus, Philosopher's Index, ACM)
**Search:** AI + ethics + mental health (with variants)
**Sample:** 101 articles (after screening)
**Analysis:** Thematic clustering - theme = concern in >2 articles

## Relevance
- Comprehensive ethics taxonomy
- Conversational AI specific (chatbots, virtual agents)
- Identifies priority concerns
- 101 articles = robust synthesis

## My Notes
**Safety/Harm = #1 Priority (52%):**
- Suicidality: What if chatbot mishandles suicidal crisis?
- Harmful suggestions: AI gives bad advice
- Dependency: Users become over-reliant, avoid human help

**Justice (41%) = Often Overlooked:**
- Digital divide: who has access, skills, devices?
- Health inequalities: AI may worsen disparities
- Particularly relevant for Turkey: rural/urban, SES, education gaps

**Black Box Problem:**
- Opaque algorithms → can't explain why recommendation made
- Undermines trust in both AI and providers using it
- Transparency critical but technically challenging

**Empathy/Humanness (29%):**
- Central debate: can/should AI be empathic?
- Simulated empathy vs genuine empathy
- Risk: illusion of understanding when none exists
- Connects to Yıldız's therapeutic relationship concerns

**Accountability Gaps:**
- If AI harms patient, who is responsible?
- Developer? Clinician? Institution? Patient?
- Legal/regulatory frameworks lag behind technology

**Turkish Application:**
- Which themes most salient in Turkish context?
- Justice/access likely critical (inequalities)
- Empathy/humanness (cultural emphasis on warmth)
- Accountability (regulatory framework weak?)

## Rating: ⭐⭐⭐⭐⭐ (comprehensive, well-structured taxonomy, 101 articles)
**Date processed:** 2024-12-13
