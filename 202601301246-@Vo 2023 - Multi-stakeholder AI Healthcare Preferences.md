---
title: 'Multi-stakeholder preferences for the use of artificial intelligence in healthcare:
  A systematic review and thematic analysis'
authors: Vinh Vo, Gang Chen, Yves Saint James Aquino, Stacy M. Carter, Quynh Nga Do,
  Maame Esi Woode
year: '2023'
source: Social Science & Medicine
doi: 10.1016/j.socscimed.2023.116357
tags:
type: source
status: reviewed
added: '2025-12-24'
relevance: high
permalink: efforts/research/public-attitudes-ai-mental-health/sources/paper-notes/vo-2023-multi-stakeholder-ai-healthcare-preferences
---

# Vo 2023 - Multi-stakeholder AI Healthcare Preferences
#lit #ai-attitudes

Related: [[202601301240-AI User Attitudes]]


**Document Type:** Systematic review + thematic analysis (PRISMA guidelines)

**Sample:** 105 publications included (7,490 screened) from Jan 2001 - Aug 2021

**Stakeholder Breakdown:**
- Health professionals: 56 studies (53%)
- General public: 35 studies (33%)
- Patients: 20 studies (19%)

---

## Key Findings

### Overall Attitudes
**Positive attitudes predominate** (47% of studies), but with significant concerns:
- **Data privacy** - most persistent concern across all groups (38% of studies)
- **Empathy challenge** - 90% of participants across all groups indicated AI's main challenge is delivering empathic care
- **Job replacement fears** - Mixed among patients (6 studies), but **health professionals strongly indicated AI would NOT replace them** (22 studies, 47%)
- **Trust in human doctors** - Majority trust human doctors regardless of AI performance (10 studies for public/patients, 5 for professionals)

### Knowledge & Familiarity (n=18 studies)
**General public & patients:**
- No or limited knowledge of AI (3 studies)
- Associate AI with: cognition (games), machines (chatbots, robots), or fear

**Health professionals:**
- 60% expressed lack of experience/exposure to AI (11 studies)
- Concerns about limited understanding of how AI works (2 studies)
- Skepticism: AI capabilities exaggerated by industry/media (3 studies)

### Perceived Benefits (n=49 studies)

**Shared expectations (all groups):**
- Test accuracy improvement
- Medical error reduction
- Reduced workload for health professionals
- Lower health expenses
- Increased healthcare access
- Reduced waiting times

**Health professionals' priorities:**
1. **Efficiency** (37%): Clinical/non-clinical workload reduction, time savings
2. **Enhanced medical capabilities**: Reduce errors, increase accuracy, sharpen clinical skills, improve risk detection
3. **Better patient-clinician relationship**: More time for patient care (9 studies)

### Perceived Risks (n=47 studies)

**Primary concerns (all groups):**
- **Data privacy** (38% of studies with this theme)
- **Reduced professional autonomy**
- **Algorithmic bias**
- **Healthcare inequities**
- **Deskilling of health professionals** (23%): Reduced clinical judgment, fewer opportunities for practice

**Specific to professionals:**
- **Greater burnout** from learning AI skills (8 studies)
- **Bias from unrepresentative training data** → reduced trust in professionals
- **Salary reduction** conceivable (3 studies)

### Challenges (n=30 studies)

**Primary challenge across ALL groups:**
- **Delivering empathic care** (n=27, **90%**) - This is THE major theme

**Other challenges:**
- Lack of evidence-based AI technologies
- Technical uncertainties (infrastructure failure, malfunction)
- Suitability issues: Not useful for every patient, emergencies, or complications
- Lack of interpretability and explainability

### AI Acceptability (n=59 studies)

**Key factors influencing acceptance:**

*For general public/patients:*
- **AI explainability** - want to understand how it works
- **Affordable costs**
- **Technology familiarity** (mixed evidence)
- **Trust by health professionals** - mutual reliance identified

*For health professionals:*
- **Trust by patients** - mutual reliance
- **Easy to understand decisions** (associated with trust)
- **High predictive accuracy**
- **Safety**
- **Ease of use**

**Critical finding:** When accuracy vs. explainability conflict, participants **preferred accuracy over explainability**

### AI Development (n=11 studies)

**Validation needs:**
- AI algorithms validated before use (6 studies from patients/public)
- More RCTs rather than just observational studies (professionals)

**Transparency & explainability:**
- Decision-making mechanisms transparent and accessible (3 studies, professionals)
- AI auditability - not a "black box" (2 studies)
- Results must be understandable to health professionals (4 studies)

**Stakeholder engagement:**
- **Clinicians must be part of development** (8 studies, 72% of professionals)
- Broader consultation needed (patients, public, professionals) (4 studies)
- Patients/public want voice in development to understand AI diagnosis/treatment

**Patient utility matters more than automation** (6 studies, 55%)

### AI Implementation (n=27 studies)

**Facilitating factors:**
- **Education and training** for health professionals (n=26, **96%** - strongest message)
- Patient awareness of AI (5 studies)
- Health professionals ready and capable
- Reimbursement/subsidy policies

**Hindering factors:**
- Lack of familiarity, trust, regulatory clarity (5 studies)
- Physician disapproval (for public)
- Lack of knowledge, guidance, financial support, data (9 studies, professionals)
- High costs
- Inconsistent AI performance

**Critical need:** Education to **reskill rather than deskill** (7 studies)

### AI Regulations (n=24 studies)

**Data-related issues:**
- Data access allowed IF governance standards met, societal benefit demonstrated (4 studies)
- Guidelines needed for: anonymizing data, reliably labeling data
- Balance data privacy risks with AI usefulness

**Public willingness:**
- Willing to share **anonymized data** for AI development (3 studies)
- Concerns about sharing with insurance/technology companies

**Responsibility mechanisms:**
- **Who is accountable for adverse events?** (13 studies, 54%)
 - Health professionals in charge (9 studies, 38%)
 - BUT many health professionals **not prepared** or **unclear** about responsibility
 - Shared responsibility recommended (government, AI developers, health professionals, organizations, patients)

### Human-AI Relationship (n=17 studies)

**Clear consensus:**
- **AI should assist, NOT replace human doctors** (6 studies, patients/public; 5 studies, professionals)
- Health professionals maintain professional autonomy (3 studies for each group)
- Health professionals supervise AI (4 studies)
- AI as **second opinion** to reconfirm conclusions (4 studies)

**Ideal synergy:**
- AI responsible for diagnostic analysis
- Human doctors provide final results

**Mixed responses on choosing AI vs. human:**
- Some choose AI if better performance (asthma, skin cancer, radiology)
- Others choose human doctors if equally skilled
- **Majority trust human doctors no matter how well AI performs** (10 studies)

---

## Methodology

### Search Strategy
- **Databases:** Scopus, CINAHL, PubMed, Medline, Embase, PsychInfo (6 total)
- **Grey literature:** Search engines, targeted websites, thesis databases
- **Time frame:** Jan 2001 - Aug 2021
- **Search terms:** (1) Preferences terms, (2) AI terms, (3) Health context terms

### Screening Process
- 7,490 records identified → 5,827 after deduplication
- 247 full-text screened → **105 included** (91 peer-reviewed + 14 grey literature)

### Data Analysis
- **Design:** Data-based convergent synthesis (thematic analysis)
- **Tool:** NVivo 12
- **Frequency categories:** Low (<10%), Medium (10-50%), High (>50%)
- Excluded "low" frequency themes from analysis
- **9 analytical themes** identified

### Quality Assessment
- **MMAT (Mixed Methods Appraisal Tool)** for peer-reviewed
- **AACODS** for grey literature
- Quality mixed but acceptable (see detailed assessment in Supplementary)

### Study Characteristics
- **Study type:** 67% quantitative, 20% qualitative, 13% mixed methods
- **Health focus:** Radiology (13%), Surgery (9%), Mental health (5%), Cancer (10%), Others (63%)
- **Geographic distribution:** 80% high-income countries, USA leads (38%), followed by UK (17%), China (7%)
- **AI exposure:** Only **10% used simulated AI applications**, 12% hypothetical scenarios, 77% no direct exposure
- **AI use:** 64% diagnosis/treatment applications

---

## Relevance to This Project

### Critical Validation of Research Gap

**Direct quote (p. 5):**
> "Most studies focus on healthcare professionals or students, with limited research on the general public in Turkey and other non-Western countries."

**Research Gaps Matrix (from paper):**

| Population | Attitude Measurement | Digital Literacy Impact | AI Anxiety/Barriers | Cultural/Religious Factors |
|------------|---------------------|------------------------|---------------------|---------------------------|
| Healthcare Professionals | 4 studies | 2 studies | 3 studies | 1 study |
| Students | 3 studies | 2 studies | 2 studies | **GAP** |
| **General Public** | **1 study** | **GAP** | **GAP** | **GAP** |
| Rural Populations | **GAP** | **GAP** | **GAP** | **GAP** |
| Culturally Diverse Groups | **GAP** | **GAP** | **GAP** | **GAP** |

**Our project directly addresses the highlighted gaps.**

### Implications for Survey Design

**Measurement Domains Identified (from findings):**
1. **Willingness to use** AI for mental health
2. **Trust** in AI vs. human therapists
3. **Privacy concerns** (persistent barrier)
4. **Knowledge** about AI capabilities/limitations
5. **AI anxiety** levels
6. **Digital literacy** (strong predictor)
7. **Empathy expectations** (90% consider this AI's main challenge)
8. **Demographics** + mental health literacy

**Critical insight for mental health context:**
- **Empathy is THE challenge** (90% across all stakeholder groups)
- Mental health specifically mentioned in 5 studies
- Public willing to use AI **IF** trusted by health professionals (mutual reliance)

### Sample Considerations

**Based on gaps identified:**
- Target **urban AND rural** populations (gap in literature)
- Include **digital literacy assessment** (key moderator)
- Stratify by **age, education, socioeconomic status**
- Consider **cultural/religious factors** in item wording (systematically underexplored)
- Focus on **general public** NOT professionals (major gap in Turkey)

### Validated Instruments

**No specific instruments for general public identified** - this is a GAP and opportunity!

Professional instruments exist but not validated for public:
- Could adapt items for general public
- Need bilingual instrument (Turkish/English)
- Consider scenario-based approaches (only 3 SP studies found)

---

## Thematic Framework: 9 Analytical Themes

### 1. Knowledge/Familiarity of AI (n=18)
- Limited/no knowledge (public/patients)
- Lack of exposure (60% health professionals)
- Concerns about exaggerated capabilities

### 2. Perceived Benefits (n=49)
- Efficiency gains
- Enhanced medical capabilities
- Improved patient-clinician relationship
- Better patient understanding

### 3. Perceived Risks (n=47)
- Data privacy (38%)
- Increased healthcare disparities
- Job evolution concerns
- Deskilling (23%)
- Greater burnout

### 4. Perceived Challenges (n=30)
- **Empathic care delivery (90%)**
- Lack of evidence-based technologies
- Technical uncertainties
- Suitability issues

### 5. AI Acceptability (n=59)
- Generally positive (47% vs. 19% negative)
- Key factors: explainability, affordability, trust, accuracy
- Mutual reliance between patients and professionals

### 6. AI Development (n=11)
- Validation needs
- Transparency and explainability
- Stakeholder engagement (72% professionals want involvement)
- Patient utility over automation

### 7. AI Implementation (n=27)
- **Education/training critical (96%)**
- Facilitators: awareness, readiness, reimbursement
- Barriers: lack of familiarity, trust, regulation

### 8. AI Regulations (n=24)
- Data access and privacy
- Responsibility mechanisms (54% unclear)
- Shared accountability recommended

### 9. Human-AI Relationship (n=17)
- AI assists, not replaces
- Professional autonomy maintained
- Trust in human doctors persists

---

## Critical Assessment

### Strengths
1. **Comprehensive multi-stakeholder perspective** - first systematic review to include all three groups
2. **Robust methodology** - PRISMA guidelines, rigorous screening, quality assessment
3. **Large sample** - 105 studies synthesizing perspectives from thousands of participants
4. **Thematic synthesis approach** - allows integration of qualitative and quantitative data
5. **Validates our research gap** - explicitly identifies lack of general public research in Turkey

### Limitations
1. **Sample quality concerns** - 75% unclear sampling strategy, mostly non-probabilistic convenience samples
2. **Limited exposure to AI** - 77% no direct AI exposure, only 10% interacted with simulated AI
3. **Geographic bias** - 80% high-income countries, US/UK dominate
4. **English-only** - may miss non-Western perspectives
5. **Publication period** - ends Aug 2021, rapid changes in AI since then

### Implications
- Attitudes measured without actual AI experience - **stated preferences** may differ from **revealed preferences**
- Need for scenario-based or stated preference studies to address familiarity gap
- Opportunity for Turkey-specific research on general public

---

## Methodological Insights for Our Study

### What Works
- **Scenario-based studies** effective when AI exposure limited (13 studies used this)
- **Mixed methods** provide richer understanding (13% of studies)
- **Stated preference studies** can reveal trade-offs (only 3 found - gap!)

### What's Missing
- **Longitudinal studies** tracking attitude change over time
- **Cultural/religious factors** systematically underexplored
- **Urban-rural differences** not studied
- **General public in non-Western contexts** - major gap

### Recommendations for Our Study
1. **Use scenario-based vignettes** to address familiarity gap
2. **Include stated preference experiment** to understand trade-offs
3. **Measure digital literacy** as key moderator
4. **Include cultural/religious items** (gap in literature)
5. **Stratify urban/rural** (gap in literature)
6. **Focus on empathy concerns** (90% theme) - especially relevant for mental health

---

## Turkish Papers Cited

**Same 5 papers** as Consensus synthesis:

1. **Satıcı et al. (2025)** - AIAS-4 Turkish adaptation (BMC Psychology)
2. **Kaya et al. (2022)** - Personality traits & AI anxiety (Int'l J Human-Computer Interaction)
3. **Tarsuslu et al. (2024)** - Digital leadership & AI anxiety in nurses (J Nursing Scholarship)
4. **Turan & Cengiz (2025)** - NGAAIS Turkish nursing students (Nurse Education in Practice)
5. **Montag et al. (2023)** - AI and global mental health (Asian J Psychiatry)

**All focus on health professionals or students, NOT general public** ✓

---

## Key Quotes

### On Research Gap
> "To date, there has not been a systematic review that analyzes and synthesizes the results from all key stakeholders including health professionals, patients and members of the general public." (p. 2)

### On General Public Knowledge
> "Patients and the general public expressed no or limited knowledge of AI" (p. 5-6)

### On Empathy Challenge
> "Participants from both groups...indicated that the main challenge of AI is to deliver empathic care to patients (n = 27, 90%)" (p. 9)

### On Job Replacement
> "Health professionals strongly indicated that AI would not be able to completely replace their professions (n = 22, 47%)" (p. 8)

### On Education Need
> "Current and prospective health professionals...expressed strong messages on the need for more education and training on advantages and limitations of AI (n = 26, 96%)" (p. 11)

---

## Policy Implications (from paper)

1. **Knowledge deficiency identified:** If public willing to use AI despite lack of training/regulation → gap
2. **Education campaigns needed:** Targeted digital literacy interventions can improve attitudes
3. **Transparency required:** Privacy/ethics concerns persist; need clear communication
4. **Regulatory standards urgent:** Balance benefits, safety, and innovation
5. **Equitable access:** Rural and less digitally connected populations underserved
6. **Beyond algorithms:** Translation of legislation into practice needed for fairness, accountability, transparency

---

## My Notes

### Why This Paper is Foundational

This systematic review is **goldmine** for our literature review because:

1. **Validates our entire research rationale** - explicitly confirms Turkish general public gap
2. **Provides thematic framework** - 9 themes we can use to organize our findings
3. **Identifies measurement domains** - 7 key domains for survey design
4. **Confirms empathy as critical** - 90% theme especially relevant for mental health AI
5. **Shows mutual reliance** - public trusts AI IF professionals trust it (key insight)
6. **Documents persistent concerns** - privacy, bias, job evolution (not loss)

### Comparison to Consensus Synthesis

**Overlap with Consensus paper:**
- Same 5 Turkish papers cited
- Same research gap identified (general public understudied)
- Same themes emerge (empathy, privacy, trust)

**What Vo adds:**
- Multi-stakeholder comparison (can see where groups converge/diverge)
- Broader geographic scope (105 papers vs. 20)
- More detailed thematic analysis (9 themes with sub-themes)
- Explicit frequency coding (low/medium/high)
- Quality assessment details

### Questions Raised

1. **How do empathy concerns differ for mental health vs. general healthcare AI?**
 - Mental health explicitly requires empathic connection
 - Would Turkish public be MORE concerned about AI in mental health context?

2. **What cultural factors shape Turkish attitudes?**
 - Collectivism vs. individualism
 - Family orientation
 - Religiosity
 - Traditional healing practices

3. **Urban-rural digital divide in Turkey?**
 - How does access to technology shape AI attitudes?
 - Istanbul vs. rural Anatolia differences?

4. **Language barriers?**
 - Would Turkish AI (vs. English AI) affect acceptability?
 - Cultural adaptation of AI needed?

---

## Next Steps Based on This Review

1. **Obtain full texts** of 5 key Turkish papers (priority - same as Consensus)
2. **Design scenario-based survey** addressing familiarity gap
3. **Include stated preference experiment** to reveal trade-offs (accuracy vs. empathy vs. privacy)
4. **Develop cultural items** for Turkish context (family, religion, traditional healing)
5. **Stratify sampling** by urban/rural, digital literacy, age, education
6. **Focus empathy items** on mental health context specifically
7. **Consider longitudinal design** to track attitude change (gap identified)

---

## Rating

⭐⭐⭐⭐⭐ (5/5 stars)

**Rationale:**
- **Comprehensive and rigorous:** PRISMA systematic review, 105 studies, multi-stakeholder
- **Directly validates research gap:** Explicit confirmation of Turkish general public gap
- **Provides actionable framework:** 9 themes, measurement domains, validated approach
- **High-quality synthesis:** Thematic analysis with frequency coding, quality assessment
- **Policy-relevant:** Clear implications for regulation, education, implementation
- **Identifies exactly what we need to study:** General public, Turkey, mental health context, cultural factors

**This paper is THE foundational systematic review for our literature review.**

*Processed: 2025-12-24*

---

## References

Vo, V., Chen, G., Aquino, Y.S.J., Carter, S.M., Do, Q.N., & Woode, M.E. (2023). Multi-stakeholder preferences for the use of artificial intelligence in healthcare: A systematic review and thematic analysis. *Social Science & Medicine, 338*, 116357. https://doi.org/10.1016/j.socscimed.2023.116357