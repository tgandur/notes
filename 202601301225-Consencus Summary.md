---
tags:
 - ethical-readiness
 - consensus-summary
 - clinical-adoption-predictors
 - ai-ethics
 - mental-health-professionals
 - ai-adoption-intention
---

# Consencus Summary
#jots #ai_ethics

Related: [[202512011220-AI Ethics & Mental Health Professionals]]

# Yes, **mental health professionals’ knowledge of AI ethics is a significant predictor of both their adoption of AI tools and their attitudes toward AI in clinical practice**, though the relationship is nuanced and influenced by other factors.

## 1. Introduction

The integration of artificial intelligence (AI) into mental health care is accelerating, but adoption rates and attitudes among mental health professionals vary widely. A growing body of research suggests that knowledge of AI ethics—encompassing awareness of privacy, bias, transparency, and professional responsibility—plays a crucial role in shaping both the willingness to adopt AI tools and the attitudes toward their use in clinical practice. Studies consistently find that ethical readiness and AI literacy are associated with greater openness to AI adoption, while lack of ethical knowledge is a barrier to both positive attitudes and practical uptake (Cecil et al., 2025; Zhang et al., 2023; Khalil et al., 2025; Cross et al., 2024; Sharif et al., 2025; Wagner & Schwind, 2025; Turchioe et al., 2024). However, the relationship is complex, with some studies reporting mixed or context-dependent findings, highlighting the influence of additional factors such as organizational support, digital literacy, and perceived usefulness (Cecil et al., 2025; Sharif et al., 2025; Wagner & Schwind, 2025; Kleine et al., 2023; Khalil et al., 2025). This review synthesizes the current evidence on whether and how mental health professionals’ knowledge of AI ethics predicts their adoption of AI tools and their attitudes toward AI in clinical settings.

**Figure 1:** Consensus meter showing strong evidence that AI ethics knowledge predicts adoption and attitudes.

## 2. Methods

A comprehensive search was conducted across over 170 million research papers in Consensus, including sources such as Semantic Scholar and PubMed. The search strategy targeted studies examining the relationship between mental health professionals’ knowledge of AI ethics and their adoption or attitudes toward AI tools. In total, 1,034 papers were identified, 522 were screened, 344 were deemed eligible, and the top 50 most relevant papers were included in this review.

|Identification|Screening|Eligibility|Included|
|---|---|---|---|
|1034|522|344|50|

**Figure 2:** Flow diagram of the search and selection process for included studies. Twenty unique search queries were executed, focusing on predictors of AI adoption, ethical literacy, digital readiness, and professional attitudes in mental health care.

## 3. Results

### 3.1. Ethical Knowledge as a Predictor of AI Adoption

Multiple studies demonstrate that ethical readiness—defined as awareness, knowledge, and adherence to AI ethical standards—is a significant predictor of intentions to use AI tools across diagnostic, treatment, feedback, and management domains in mental health care (Cecil et al., 2025; Khalil et al., 2025). Professionals with higher AI ethics knowledge are more likely to have positive attitudes toward AI and express greater willingness to adopt these technologies (Cecil et al., 2025; Khalil et al., 2025; Zhang et al., 2023; Cross et al., 2024).

### 3.2. Impact on Attitudes Toward AI

Ethical knowledge not only predicts adoption but also shapes attitudes. Professionals with greater understanding of AI ethics tend to view AI more favorably, emphasizing its potential benefits while remaining cognizant of its risks (Cecil et al., 2025; Zhang et al., 2023; Khalil et al., 2025; Cross et al., 2024; Sharif et al., 2025; Wagner & Schwind, 2025). Conversely, lack of ethical knowledge and training is frequently cited as a barrier to both adoption and positive perception of AI in clinical settings (Cecil et al., 2025; Zhang et al., 2023; Khalil et al., 2025; Cross et al., 2024; Sharif et al., 2025; Wagner & Schwind, 2025).

### 3.3. Moderating and Contextual Factors

The relationship between AI ethics knowledge and adoption/attitudes is not absolute. Some studies find that general AI training or awareness alone does not always translate to more positive attitudes or higher adoption, suggesting that the quality and focus of ethics education matter (Sharif et al., 2025; Wagner & Schwind, 2025; Kleine et al., 2023). Other factors—such as organizational support, digital literacy, and perceived trustworthiness of AI—also play important roles in shaping adoption and attitudes (Cecil et al., 2025; Sharif et al., 2025; Wagner & Schwind, 2025; Kleine et al., 2023; Khalil et al., 2025).

### 3.4. Contrasting and Null Findings

A minority of studies report no significant association between AI ethics knowledge and adoption or attitudes, indicating that other variables (e.g., task characteristics, performance expectancy, or social influence) may sometimes outweigh ethical knowledge as predictors (Wagner & Schwind, 2025; Alimour et al., 2024). These findings highlight the need for multifaceted approaches to training and implementation.

#### Results Timeline

- **Dec 2022**
 - 1 paper: (Mccradden et al., 2022)- **Feb 2023**
 - 2 papers: (Higgins et al., 2023; Kleine et al., 2023)- **Dec 2023**
 - 1 paper: (Zhang et al., 2023)- **Jan 2024**
 - 1 paper: (Rogan et al., 2024)- **Mar 2024**
 - 1 paper: (Elyoseph et al., 2024)- **Apr 2024**
 - 1 paper: (D’Souza et al., 2024)- **Jul 2024**
 - 1 paper: (Saeidnia et al., 2024)- **Oct 2024**
 - 1 paper: (Cross et al., 2024)- **Dec 2024**
 - 1 paper: (Asman et al., 2024)- **Jan 2025**
 - 1 paper: (Gruber & Martic-Biocina, 2025)- **Feb 2025**
 - 1 paper: (U.G.Lashari et al., 2025)- **Mar 2025**
 - 1 paper: (Yıldız, 2025)- **Apr 2025**
 - 1 paper: (Cecil et al., 2025)- **May 2025**
 - 1 paper: (Chiu & Wei, 2025)- **Jun 2025**
 - 2 papers: (Whyte & Carpenter, 2025; Garcia, 2025)- **Jul 2025**
 - 3 papers: (Sharif et al., 2025; Abiodun et al., 2025; Wagner & Schwind, 2025)**Figure 3:** Timeline of key studies on AI ethics knowledge and adoption in mental health. Larger markers indicate more citations.

#### Top Contributors

|Type|Name|Papers|
|---|---|---|
|Author|Anne-Kathrin Kleine|(Cecil et al., 2025; Kleine et al., 2023)|
|Author|E. Lermer|(Cecil et al., 2025; Kleine et al., 2023)|
|Author|S. Gaube|(Cecil et al., 2025; Kleine et al., 2023)|
|Journal|_JMIR Mental Health_|(Cross et al., 2024; Rogan et al., 2024; Saeidnia et al., 2024; Elyoseph et al., 2024; Asman et al., 2024; Blease et al., 2024; Meadi et al., 2025; Wang et al., 2024)|
|Journal|_BMC Health Services Research_|(Cecil et al., 2025)|
|Journal|_Digital Health_|(Khalil et al., 2025)|

**Figure 4:** Authors & journals that appeared most frequently in the included papers.

## 4. Discussion

The evidence strongly supports the view that mental health professionals’ knowledge of AI ethics is a key driver of both their willingness to adopt AI tools and their attitudes toward these technologies (Cecil et al., 2025; Zhang et al., 2023; Khalil et al., 2025; Cross et al., 2024; Sharif et al., 2025; Wagner & Schwind, 2025; Turchioe et al., 2024). Ethical readiness—encompassing understanding of privacy, bias, transparency, and professional responsibility—consistently predicts positive attitudes and greater adoption intentions. However, the relationship is nuanced: the quality and specificity of ethics education, as well as contextual factors like organizational support and digital literacy, modulate this effect (Cecil et al., 2025; Sharif et al., 2025; Wagner & Schwind, 2025; Kleine et al., 2023; Khalil et al., 2025). Some studies report mixed or null findings, suggesting that ethical knowledge alone is not always sufficient; practical experience, perceived usefulness, and social influence also play important roles (Wagner & Schwind, 2025; Alimour et al., 2024). These findings underscore the importance of comprehensive, context-sensitive training programs that address both ethical and practical aspects of AI in mental health care.

### Claims and Evidence Table

|Claim|Evidence Strength|Reasoning|Papers|
|---|---|---|---|
|AI ethics knowledge predicts adoption of AI tools in mental health|Evidence strength: Strong (9/10)|Multiple large-scale, cross-national studies show strong, consistent associations across domains|(Cecil et al., 2025; Khalil et al., 2025; Zhang et al., 2023; Cross et al., 2024)|
|AI ethics knowledge predicts positive attitudes toward AI in practice|Evidence strength: Strong (8/10)|Robust evidence from surveys and intervention studies links ethical literacy to favorable attitudes|(Cecil et al., 2025; Zhang et al., 2023; Khalil et al., 2025; Cross et al., 2024; Sharif et al., 2025; Wagner & Schwind, 2025)|
|General AI training/awareness alone does not always predict adoption|Evidence strength: Moderate (5/10)|Some studies find mixed or null effects, highlighting the importance of content and context|(Sharif et al., 2025; Wagner & Schwind, 2025; Kleine et al., 2023; Alimour et al., 2024)|
|Organizational support and digital literacy moderate the relationship|Evidence strength: Moderate (5/10)|Evidence suggests these factors can enhance or diminish the impact of ethics knowledge on adoption/attitude|(Cecil et al., 2025; Sharif et al., 2025; Wagner & Schwind, 2025; Kleine et al., 2023; Khalil et al., 2025)|
|Task characteristics and performance expectancy may outweigh ethics|Evidence strength: Weak (3/10)|A few studies find other predictors (e.g., perceived usefulness) are more influential in some contexts|(Wagner & Schwind, 2025; Alimour et al., 2024)|
|No association between ethics knowledge and adoption in some samples|Evidence strength: Weak (2/10)|Rare, but present; highlights the need for multifactorial approaches|(Wagner & Schwind, 2025; Alimour et al., 2024)|

**Figure 5:** Key claims and support evidence identified in these papers.

## 5. Conclusion

In summary, mental health professionals’ knowledge of AI ethics is a strong and consistent predictor of both their adoption of AI tools and their attitudes toward these technologies, though the relationship is influenced by additional factors such as organizational support, digital literacy, and perceived usefulness. Comprehensive, context-sensitive ethics education is essential for fostering responsible and effective AI integration in mental health care.

### 5.1. Research Gaps

Despite the growing evidence base, several gaps remain. There is limited research on the long-term impact of ethics education, the effectiveness of different training modalities, and the interplay between ethical knowledge and other predictors (e.g., organizational culture, task fit). More research is needed on diverse professional groups and in non-Western contexts.

#### Research Gaps Matrix

|Topic / Attribute|Psychiatrists **7**|Psychologists **6**|Nurses **4**|Mixed Professions **8**|Non-Western Settings **3**|
|---|---|---|---|---|---|
|Ethics knowledge & adoption|**4**|**3**|**2**|**5**|**1**|
|Ethics knowledge & attitudes|**3**|**3**|**2**|**3**|**1**|
|Longitudinal impact of training|**GAP**|**GAP**|**GAP**|**GAP**|**GAP**|
|Organizational/contextual factors|**2**|**1**|**1**|**2**|**GAP**|

**Figure 6:** Matrix showing research coverage by profession, topic, and setting; gaps remain in longitudinal and non-Western studies.

### 5.2. Open Research Questions

Future research should address the following questions to advance understanding and practice:

|Question|Why|
|---|---|
|**What is the long-term impact of AI ethics education on adoption and attitudes among mental health professionals?**|Longitudinal studies are needed to determine if training effects persist and translate into sustained adoption.|
|**How do organizational and cultural factors interact with ethics knowledge to influence AI adoption in mental health care?**|Understanding these interactions can inform more effective, context-sensitive implementation strategies.|
|**What are the most effective modalities for delivering AI ethics education to diverse mental health professionals?**|Identifying best practices in training can maximize impact and address current knowledge gaps.|

**Figure 7:** Open research questions for future studies on AI ethics knowledge and adoption in mental health care.

In conclusion, while ethical knowledge is a key driver of AI adoption and positive attitudes among mental health professionals, a multifaceted approach—incorporating organizational, contextual, and educational strategies—is essential for responsible and effective AI integration in clinical practice.

_These papers were sourced and synthesized using Consensus, an AI-powered search engine for research. Try it at [https://consensus.app](https://consensus.app/)_

## References

Cross, S., Bell, I., Nicholas, J., Valentine, L., Mangelsdorf, S., Baker, S., Titov, N., & Alvarez-Jimenez, M. (2024). Use of AI in Mental Health Care: Community and Mental Health Professionals Survey. _JMIR Mental Health_, 11. [https://doi.org/10.2196/60589](https://doi.org/10.2196/60589)

Cecil, J., Kleine, A., Lermer, E., & Gaube, S. (2025). Mental health practitioners’ perceptions and adoption intentions of AI-enabled technologies: an international mixed-methods study. _BMC Health Services Research_, 25. [https://doi.org/10.1186/s12913-025-12715-8](https://doi.org/10.1186/s12913-025-12715-8)

Sharif, L., Almabadi, R., Alahmari, A., Alqurashi, F., Alsahafi, F., Qusti, S., Akash, W., Mahsoon, A., Poudel, D., Sharif, K., & Wright, R. (2025). Perceptions of mental health professionals towards artificial intelligence in mental healthcare: a cross-sectional study. _Frontiers in Psychiatry_, 16. [https://doi.org/10.3389/fpsyt.2025.1601456](https://doi.org/10.3389/fpsyt.2025.1601456)

Whyte, A., & Carpenter, K. (2025). AI in Psychiatry: Obstacles and Opportunities. _BJPsych Open_, 11, S76 - S76. [https://doi.org/10.1192/bjo.2025.10245](https://doi.org/10.1192/bjo.2025.10245)

, U., Shabbir, S., Shahbaz, T., & Kayani, H. (2025). THE ROLE OF AI IN PREDICTING MENTAL HEALTH DISORDERS: A CLINICAL PSYCHOLOGY PERSPECTIVE. _Journal of Medical & Health Sciences Review_. [https://doi.org/10.62019/f6zdfy58](https://doi.org/10.62019/f6zdfy58)

Zhang, M., Scandiffio, J., Younus, S., Jeyakumar, T., Karsan, I., Charow, R., Salhia, M., & Wiljer, D. (2023). The Adoption of AI in Mental Health Care–Perspectives From Mental Health Professionals: Qualitative Descriptive Study. _JMIR Formative Research_, 7. [https://doi.org/10.2196/47847](https://doi.org/10.2196/47847)

D’Souza, R., Mathew, M., Amanullah, S., Thornton, J., Mishra, V., E, M., Palatty, P., & Surapaneni, K. (2024). Navigating merits and limits on the current perspectives and ethical challenges in the utilization of artificial intelligence in psychiatry - An exploratory mixed methods study.. _Asian journal of psychiatry_, 97, 104067. [https://doi.org/10.1016/j.ajp.2024.104067](https://doi.org/10.1016/j.ajp.2024.104067)

Abiodun, O., Ajiboye, P., Salihu, M., Sulyman, D., Akinsulore, A., Obayi, O., & Salihu, H. (2025). Psychiatrists’ and trainees’ knowledge, perception, and readiness for integration of artificial intelligence in mental health care in Nigeria. _BMC Psychiatry_, 25. [https://doi.org/10.1186/s12888-025-07135-1](https://doi.org/10.1186/s12888-025-07135-1)

Gruber, E., & Martic-Biocina, S. (2025). Barriers to AI Adoption in Psychiatry: Exploring the Attitudes of Five Psychiatrists Who Do Not Use AI. _Archives of Medical Case Reports_. [https://doi.org/10.33696/casereports.7.034](https://doi.org/10.33696/casereports.7.034)

Higgins, O., Short, B., Chalup, S., & Wilson, R. (2023). Artificial intelligence (AI) and machine learning (ML) based decision support systems in mental health: An integrative review.. _International journal of mental health nursing_. [https://doi.org/10.1111/inm.13114](https://doi.org/10.1111/inm.13114)

Rogan, J., Bucci, S., & Firth, J. (2024). Health Care Professionals’ Views on the Use of Passive Sensing, AI, and Machine Learning in Mental Health Care: Systematic Review With Meta-Synthesis. _JMIR Mental Health_, 11. [https://doi.org/10.2196/49577](https://doi.org/10.2196/49577)

Chiu, S., & Wei, L. (2025). Addressing Workforce and Ethical Gaps in AI-Driven Mental Health Care: A Response to Higgins and Wilson.. _International journal of mental health nursing_, 34 3, e70075. [https://doi.org/10.1111/inm.70075](https://doi.org/10.1111/inm.70075)

Saeidnia, H., Fotami, S., Lund, B., & Ghiasi, N. (2024). Ethical Considerations in Artificial Intelligence Interventions for Mental Health and Well-Being: Ensuring Responsible Implementation and Impact. _Social Sciences_. [https://doi.org/10.3390/socsci13070381](https://doi.org/10.3390/socsci13070381)

Elyoseph, Z., Gur, T., Haber, Y., Simon, T., Angert, T., Navon, Y., Tal, A., & Asman, O. (2024). An Ethical Perspective on the Democratization of Mental Health With Generative AI. _JMIR Mental Health_, 11. [https://doi.org/10.2196/58011](https://doi.org/10.2196/58011)

Asman, O., Torous, J., & Tal, A. (2024). Responsible Design, Integration, and Use of Generative AI in Mental Health. _JMIR Mental Health_, 12. [https://doi.org/10.2196/70439](https://doi.org/10.2196/70439)

Garcia, G. (2025). The role of AI in transforming psychiatric-mental health care: Enhancing the role of psychiatric-mental health nurse practitioners.. _Nursing outlook_, 73 4, 102461. [https://doi.org/10.1016/j.outlook.2025.102461](https://doi.org/10.1016/j.outlook.2025.102461)

Mccradden, M., Hui, K., & Buchman, D. (2022). Evidence, ethics and the promise of artificial intelligence in psychiatry. _Journal of Medical Ethics_, 49, 573 - 579. [https://doi.org/10.1136/jme-2022-108447](https://doi.org/10.1136/jme-2022-108447)

Wagner, J., & Schwind, A. (2025). Investigating psychotherapists’ attitudes towards artificial intelligence in psychotherapy. _BMC Psychology_, 13. [https://doi.org/10.1186/s40359-025-03071-7](https://doi.org/10.1186/s40359-025-03071-7)

Kleine, A., Kokje, E., Lermer, E., & Gaube, S. (2023). Attitudes Toward the Adoption of 2 Artificial Intelligence–Enabled Mental Health Tools Among Prospective Psychotherapists: Cross-sectional Study. _JMIR Human Factors_, 10. [https://doi.org/10.2196/46859](https://doi.org/10.2196/46859)

Yıldız, E. (2025). Artificial Intelligence in Mental Health Nursing: Balancing Clinical Efficiency and the Human Touch—A Quest for a New Synthesis. _Journal of Psychiatric and Mental Health Nursing_, 32, 946 - 952. [https://doi.org/10.1111/jpm.13173](https://doi.org/10.1111/jpm.13173)

Blease, C., Worthen, A., & Torous, J. (2024). Psychiatrists’ experiences and opinions of generative artificial intelligence in mental healthcare: An online mixed methods survey. _Psychiatry Research_, 333. [https://doi.org/10.1016/j.psychres.2024.115724](https://doi.org/10.1016/j.psychres.2024.115724)

Meadi, M., Sillekens, T., Metselaar, S., Van Balkom, A., Bernstein, J., & Batelaan, N. (2025). Exploring the Ethical Challenges of Conversational AI in Mental Health Care: Scoping Review. _JMIR Mental Health_, 12. [https://doi.org/10.2196/60432](https://doi.org/10.2196/60432)

Wang, X., Zhou, Y., & Zhou, G. (2024). The Application and Ethical Implication of Generative AI in Mental Health: Systematic Review. _JMIR Mental Health_, 12. [https://doi.org/10.2196/70610](https://doi.org/10.2196/70610)

Khalil, A., Bakheet, J., Atiya, D., Jehani, R., Abdullah, R., & Haddad, M. (2025). Cultivating artificial intelligence (AI) competence and shaping attitudes among psychiatric hospital nurses: A quasi-experimental study. _Digital Health_, 11. [https://doi.org/10.1177/20552076251336515](https://doi.org/10.1177/20552076251336515)

Alimour, S., Alnono, E., Aljasmi, S., Farran, H., Alqawasmi, A., Alrabeei, M., Shwedeh, F., & Aburayya, A. (2024). The quality traits of artificial intelligence operations in predicting mental healthcare professionals’ perceptions: A case study in the psychotherapy division. _Journal of Autonomous Intelligence_. [https://doi.org/10.32629/jai.v7i4.1438](https://doi.org/10.32629/jai.v7i4.1438)

Turchioe, M., Desai, P., Harkins, S., Kim, J., Kumar, S., Zhang, Y., Joly, R., Pathak, J., Hermann, A., & Benda, N. (2024). Differing perspectives on artificial intelligence in mental healthcare among patients: a cross-sectional survey study. _Frontiers in Digital Health_, 6. [https://doi.org/10.3389/fdgth.2024.1410758](https://doi.org/10.3389/fdgth.2024.1410758)