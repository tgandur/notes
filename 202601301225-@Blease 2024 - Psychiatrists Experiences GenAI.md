---
title: >-
 Psychiatrists' experiences and opinions of generative artificial intelligence
 in mental healthcare An online mixed methods survey
authors: Charlotte Blease, Abigail Worthen, John Torous
year: 2024
source: Psychiatry Research
doi: 10.1016/j.psychres.2024.115724
tags:
 - clinical-adoption
 - burnout-reduction
 - training-needs
 - psychiatrists
 - generative-ai
 - mixed-methods-research
type: source
status: reviewed
added: 2024-12-13T00:00:00.000Z
relevance: high
---

# Blease 2024 - Psychiatrists Experiences GenAI
#lit #ai_ethics

Related: [[202512011220-AI Ethics & Mental Health Professionals]]


## Key Findings

1. **High Adoption Rate**: 44% of psychiatrists used ChatGPT-3.5 and 33% used GPT-4.0 to assist with clinical questions within ~1 year of launch (Nov 2022 - Oct 2023)

2. **Documentation as Primary Benefit**: 70% agreed documentation will be/is more efficient; administrative burden reduction cited as major benefit

3. **Patient Usage Anticipated**: 75% believe majority of patients will consult AI tools before seeing a doctor; 63% think patients will use them to understand medical records

4. **Training Gap**: 90% agreed clinicians need more support/training in understanding these tools

5. **Mixed Opinions on Impact**: Divergent views on value in clinical practice - some enthusiastic about benefits (access, quality), others concerned about harms (errors, bias, privacy, erosion of human connection)

## Methodology

**Design:** Mixed methods online survey (quantitative + qualitative open-ended responses)

**Sample:** 138 APA-affiliated psychiatrists (18% response rate from 811 invited); recruited from attendees of "AI in Psychiatry: What APA Members Need to Know" course (Aug 2023)
- 54% male, 42% female
- Diverse age groups
- U.S. and international APA members

**Data Collection:**
- October 10-25, 2023 (administered ~1 year after ChatGPT launch)
- 3-minute online survey
- Three sections: (1) Use of LLM-powered chatbots in clinical practice, (2) Effects on practice (4-point Likert), (3) Patients' use of tools
- Optional open-ended question for additional comments
- Content analysis of qualitative responses (47% left comments, 2412 words total)

## Relevance to My Research

**Why it matters:**
First empirical study exploring psychiatrists' experiences and opinions about generative AI (specifically LLMs like ChatGPT/GPT-4) in mental healthcare. Provides baseline data on early adoption patterns, perceived benefits/risks, and training needs among U.S. psychiatrists. Critical for understanding professional perspectives that will shape AI implementation in clinical practice.

**Turkish context:**
- Highlights universal need for training/guidance that applies to Turkish context
- Documents privacy concerns relevant across cultures
- Shows professionals' mixed opinions even in technologically advanced setting - suggests similar concerns will emerge in Turkey
- Administrative burden reduction resonates with Turkish MHPs facing documentation pressures
- Model for surveying Turkish psychiatrists/psychologists about AI attitudes

## Important Quotes

> "Administrative tasks remain a leading source of burnout among all clinicians including psychiatrists who seek help, including from the assistance of AI" (p. 1)

> "Chatbots such as GPT-4 are not yet regulated, and in June 2023, the American Psychiatric Association (APA) issued a statement cautioning that physicians should not be using them to undertake clinical work at this time" (p. 1)

> "I definitely do NOT use ChatGPT to make clinical diagnoses or answer any clinical questions requiring factual answers, such as med interactions. Unfortunately, that's exactly what I've seen people do, even docs whom I know are quite computer savvy." (#175, F, Yes) (p. 4)

> "I am very concerned about reliability of these tools. Ppl talk about 'hallucinations' or 'confabulations' but let's be real, AI has been shown to be deceitful or LIE if the system doesn't know the answer. I find this to be sociopathic. Also, AI systems are created by humans and will definitely replicate the same structural racism and biases /-isms that we all carry." (#59, Prefer Not to Say, No) (p. 4)

> "I'm terrified of being replaced by AI and being unable to pay my bills (student loans)" (#61, F, No) (p. 4)

> "AI may be helpful in some ways, but those physicians who primarily rely on it may be the types who follow 'recipes' strictly at the cost of innovation. It may result in us physicians operating in a more robotic fashion… Medicine will become more conveyor belt like" (#154, F, No) (p. 5)

> "I feel like people may get upset by having their problems handed off to a machine as though they weren't worthy of a human's attention" (#40, M, No) (p. 5)

## Limitations

**Study limitations:**
- Convenience sample from AI course attendees (selection bias - may be more interested/knowledgeable)
- Low 18% response rate
- Non-probability sampling limits generalizability
- Survey items ambiguous about timeframe (current vs. future effects)
- Brief qualitative responses precluded full thematic analysis
- No demographic stratification for correlative analyses
- No distinction between actual experience vs. anticipated effects

**What's missing for my research:**
- Non-Western/U.S. perspectives
- Psychologists and other MHP disciplines (only psychiatrists)
- Cultural factors affecting attitudes
- Detailed frequency of use data
- Comparative analysis by demographics (age, gender, workplace)
- Patients' perspectives
- Specific training needs identified
- Turkish or Middle Eastern contexts entirely absent

## My Notes

### Professional Attitudes
**Enthusiastic camp**: See "revolutionary" potential, benefits to access/quality, improved patient preparation for appointments, efficiency gains

**Skeptical camp**: Fear job replacement, concern about "robotic" medicine, worry about loss of creative/complex thinking, see tools as "BAD IDEA" for patient care

**Pragmatic middle**: Recognize both benefits (documentation) and limitations (hallucinations, bias), want to use as "co-pilot" not replacement, call for better training/guidance

**Key tension**: Documentation efficiency vs. clinical decision-making - most comfortable with former, very cautious about latter

### Ethical Concerns Raised
1. **Privacy**: Concerns about HIPAA compliance, data harvesting, corporate ownership; APA/AMA cautions against entering patient data
2. **Bias/Discrimination**: Algorithmic discrimination risks perpetuating gender, race, disability biases; may worsen healthcare inequities
3. **Accuracy**: "Hallucinations," fabricated information (36% error rate in one study), "confidently wrong" responses
4. **Transparency**: Lack of regulatory oversight (as of Oct 2023)
5. **Informed Consent**: Complex terms/conditions make meaningful consent unfeasible

### Barriers to Adoption
- Regulatory uncertainty (no clear guidance as of survey)
- Privacy/HIPAA compliance concerns
- Lack of training and professional support
- Accuracy/reliability concerns
- Fear of job displacement
- Concern about erosion of clinical skills

### Training Needs
- 90% want more support/training (strongest finding)
- Need for understanding limitations (hallucinations, biases)
- Best practices for appropriate use
- Privacy/HIPAA compliance education
- How to evaluate quality of AI outputs
- Integration into clinical workflow

### Cultural Factors
- U.S.-centric sample limits cultural insights
- Mentions EU AI Act (Dec 2023) as more protective than U.S.
- Privacy regulations stricter in EU than U.S.
- No exploration of cultural attitudes toward AI in healthcare

### Future of Profession Theme
Four sub-themes identified:
1. **Documentation efficiencies** (largest theme) - automate note-writing, reduce admin burden
2. **Benefits and harms** - mixed optimism and concern
3. **Future of profession** - will it replace psychiatrists or create "AI co-pilots"?
4. **Patient-doctor relationship** - will strengthen dialogue or undermine human connection?

## Connections

- [[Cross 2024 - AI Use Community MH Professionals Survey]] - Similar survey methodology, broader MHP sample
- [[Wang 2024 - GenAI Applications Mental Health]] - Systematic review providing context for this empirical study
- [[Khalil 2025 - AI Competence Psychiatric Nurses]] - Complementary focus on training/competence building
- Contrast with Turkish MHP studies (when available) re: cultural attitudes
- Links to broader debates about AI in medicine, automation of professional work

---
**Rating:** ⭐⭐⭐⭐⭐
**Date processed:** 2024-12-13

**Why 5 stars:**
- First empirical study of psychiatrists' GenAI experiences post-ChatGPT
- Mixed methods provides depth
- Captures critical early adoption period
- Identifies key themes highly relevant to my research (training needs, ethical concerns, professional attitudes)
- Well-designed despite limitations
- Strong relevance to Turkish MHP research questions
