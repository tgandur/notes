---
tags:
title: compass_artifact_wf-9dff0135-642d-4edb-afb8-720b130025d0_text_markdown
type: note
permalink: efforts/research/ai-clinical-psychology-ethics/notes/compass-artifact-wf-9dff0135-642d-4edb-afb8-720b130025d0-text-markdown
---

# compass_artifact_wf-9dff0135-642d-4edb-afb8-720b130025d0_text_markdown
#jots #ai_ethics

Related: [[202512011220-AI Ethics & Mental Health Professionals]]


**Turkish mental health professionals have limited but growing research attention regarding AI adoption**, with only one direct qualitative study (2024) examining their attitudes, revealing cautious optimism tempered by significant ethical concerns about therapeutic relationships and privacy. The broader literature on AI in Turkish healthcare provides foundational context, but a critical research gap exists for large-scale empirical studies specifically targeting psychologists, psychiatrists, and counselors in Turkey—making the proposed research question highly timely and necessary.

This literature review examines Turkish academic sources from 2020-2025 on AI attitudes, ethics, and readiness among mental health professionals, drawing from TR Dizin, DergiPark, PubMed, and institutional sources to address the research question: *"Türkiye'de görev yapan ruh sağlığı profesyonellerinin yapay zekâ ve yapay zekâ etiğine ilişkin tutum, bilgi ve klinik kullanımına yönelik hazırbulunuşluk düzeyleri nedir ve bu düzeyler demografik ve mesleki özelliklere göre nasıl farklılaşmaktadır?"*

---

## Only one direct empirical study examines Turkish mental health professionals' AI views

The most directly relevant study to the research question is **Gültekin & Şahin (2024)**, published in *Cyberpsychology: Journal of Psychosocial Research on Cyberspace*. This qualitative investigation interviewed **13 mental health professionals** (9 psychologists, 3 psychiatrists, 1 psychological counselor) with AI expertise working in Turkey.

**Key findings reveal a cautiously optimistic stance**:
- Participants viewed AI as unable to replace clinicians but potentially valuable as a "functional assistant"
- **Perceived advantages** included increased client satisfaction, improved accessibility, reduced stigma, advanced data analysis, and decreased workload
- **Primary concerns** centered on AI's inability to establish therapeutic alliance and empathy, reliability questions, responsibility attribution, and privacy/security vulnerabilities
- Mental health was predicted to be among the **last fields affected by AI transformation** due to the centrality of human relationships
- Notably, participants showed **limited awareness of ethical issues** including data ownership, algorithmic opacity ("black box" problems), and bias

| Citation | DOI | Study Type | Sample |
|----------|-----|------------|--------|
| Gültekin, M. & Şahin, M. (2024). "The use of artificial intelligence in mental health services in Turkey: What do mental health professionals think?" *Cyberpsychology*, 18(1), Article 6 | 10.5817/CP2024-1-6 | Qualitative (semi-structured interviews) | 13 mental health professionals |

A second relevant empirical study by **Aktan, Turhan & Dolu (2022)** in *Computers in Human Behavior* surveyed **872 educated Turkish adults** on AI-based psychotherapy preferences. While not targeting professionals specifically, it found that **55% perceived AI-based psychotherapy positively**, with significant differences between profession groups—those in mental health fields showed different attitudes compared to technical/engineering professionals. Previous AI experience predicted positive attitudes toward AI-based psychotherapy.

| Citation | DOI | Study Type | Sample |
|----------|-----|------------|--------|
| Aktan, M.E., Turhan, Z., & Dolu, İ. (2022). "Attitudes and perspectives towards the preferences for artificial intelligence in psychotherapy." *Computers in Human Behavior*, 133, Article 107273 | 10.1016/j.chb.2022.107273 | Cross-sectional survey | 872 adults in Turkey |

---

## Broader Turkish healthcare studies reveal generally positive but nuanced AI attitudes

While direct mental health professional research remains limited, **substantial literature exists on Turkish healthcare workers' AI attitudes**, providing important comparative context and methodological templates.

### Turkish nurses show predominantly positive attitudes with low anxiety

Multiple studies document Turkish nurses' AI perceptions:

**Tarsuslu, Agaoglu & Bas (2024)** surveyed **439 nurses** across three Turkish regions, finding **82.7% held positive attitudes toward AI** while 82.7% reported low or medium AI anxiety. Digital leadership perception showed significant positive correlation with AI attitudes (r = 0.468, p < 0.01) and negative correlation with AI anxiety (r = -0.434, p < 0.01). Key demographic finding: 66.3% knew about AI use in healthcare, but only 27.3% wanted AI more involved in their lives.

**Kaplan & Uçar (2024)** examined **737 nurses** from three Eastern Turkish provinces (Muş, Bingöl, Adıyaman), confirming highly positive attitudes using the General Attitudes toward Artificial Intelligence Scale (GAAIS). Geographic variation emerged, with significant differences in both positive (p < 0.05) and negative (p < 0.01) attitude subscales between provinces. Importantly, nurses continued using AI despite expressing concerns about human replacement.

**Tuncer & Tuncer (2024)** found among **288 nurses** that 48.3% knew about ChatGPT/AI programs, 27.8% had used them, and **84.4% believed nurses should receive AI awareness training**. Users demonstrated higher positive attitude subscale scores. Notably, an author from the Department of Psychiatric Nursing at Dokuz Eylül University contributed to this study.

| Citation | Journal | Sample | Key Finding |
|----------|---------|--------|-------------|
| Tarsuslu, Agaoglu & Bas (2024) | *J Nursing Scholarship*, 57(1):28-38 | 439 nurses | 82.7% positive attitudes; digital leadership correlates with AI acceptance |
| Kaplan & Uçar (2024) | *Work*, 80(3):1380-1386 | 737 nurses | Regional variation in attitudes; generally positive |
| Tuncer & Tuncer (2024) | *Digital Health*, Vol 10 | 288 nurses | 84.4% support AI awareness training |

### Healthcare workers demonstrate readiness but express ethical concerns

**Boyacı & Söyük (2025)** assessed AI readiness among **195 healthcare workers** at Istanbul University-Cerrahpaşa, finding staff prepared for medical AI use with positive organizational change perceptions. **Higher AI readiness** emerged among males, physicians, and internal sciences professionals. Higher organizational change openness was associated with postgraduate education, surgical specialties, and nursing roles.

**Elgin & Elgin (2024)** conducted the most ethics-focused Turkish healthcare study, interviewing **23 professionals** including physicians, nurses, administrators, and medical ethicists about AI-driven clinical decision support systems. Five thematic areas emerged: **balancing efficiency and equity**, transparency/explicability importance, shifting professional roles, data usage ethics, and patient-centered care preservation. Participants acknowledged AI's potential while expressing concerns about exacerbating disparities, interpretability needs, and privacy.

| Citation | Journal | DOI | Key Themes |
|----------|---------|-----|------------|
| Elgin & Elgin (2024) | *BMC Medical Ethics*, 25(1):148 | 10.1186/s12910-024-01151-8 | Transparency, equity, role shifts, data ethics, patient-centered care |

---

## Turkish theoretical and review literature establishes conceptual foundations

### Core review articles address AI in mental health services

**Gültekin (2022)** authored a comprehensive Turkish-language literature review titled *"Yapay Zekânın Ruh Sağlığı Hizmetlerinde Kullanımına İlişkin Fırsatlar ve Sorunlar"* (Opportunities and Problems of Using AI in Mental Health Services) in *İnsan ve Toplum* (Human and Society). This foundational work covers fourth industrial revolution concepts, AI/machine learning characteristics, and applications in diagnosis, prediction, treatment, and evaluation. The author identifies advantages (better diagnosis, reduced workload, easier access, less stigmatization, lower costs) and disadvantages (**ethical/legal concerns, empathy limitations, discrimination risks**).

| Citation | DOI | Source |
|----------|-----|--------|
| Gültekin, M. (2022). "Yapay Zekânın Ruh Sağlığı Hizmetlerinde Kullanımına İlişkin Fırsatlar ve Sorunlar." *İnsan ve Toplum*, 12(3): 121-158 | 10.12658/M0664 | DergiPark |

**Turan, Gülşen & Yılmaz (2022)** published *"Psikiyatrik Bozukluklarda Yapay Zeka Uygulamaları"* (AI Applications in Psychiatric Disorders) in *Ankara Üniversitesi Tıp Fakültesi Mecmuası*, indexed in TR Dizin. This review examines AI's role across various psychiatric conditions, current applications, and limitations. Authors are affiliated with Karadeniz Technical University (Child and Adolescent Psychiatry), Ankara University (Interdisciplinary AI Technologies), and the Ministry of Health.

| Citation | DOI | Indexed |
|----------|-----|---------|
| Turan, B., Gülşen, M., & Yılmaz, A.E. (2022). "Psikiyatrik Bozukluklarda Yapay Zeka Uygulamaları." *Ankara Üniversitesi Tıp Fakültesi Mecmuası*, 75(1): 56-62 | 10.4274/atfm.galenos.2022.36002 | TR Dizin |

Additional theoretical works include:
- **Ülker & Akkan (2023)** – Review of digital phenotyping, virtual therapists, VR, and smart mobile applications in mental health (*Fenerbahçe Üniversitesi Sosyal Bilimler Dergisi*)
- **Konyalı et al. (2024)** – Overview of AI in psychology applications (*Journal of Kocaeli Health and Technology University*)
- **Legal liability analysis** examining AI mental health applications under Turkish, European, and Common Law frameworks (*Psikiyatride Güncel Yaklaşımlar*)

---

## Turkish AI ethics frameworks provide regulatory context without mental health specificity

### National strategy positions healthcare as a priority sector

Turkey's **National Artificial Intelligence Strategy 2021-2025** (updated July 2024) identifies healthcare as one of six priority thematic areas. The strategy, issued by the Presidential Digital Transformation Office and Ministry of Industry and Technology, mandates that "AI projects be conducted efficiently and in accordance with ethical principles." Core principles include **transparency, accountability, safety, fairness, privacy protection, and human oversight**—all applicable to mental health AI but without sector-specific guidance.

### Data protection authority provides sensitive data guidelines

**KVKK (Personal Data Protection Authority)** has issued multiple AI-related documents:
- *"Yapay Zekâ Alanında Kişisel Verilerin Korunmasına Dair Tavsiyeler"* (September 2021) – General AI data protection guidelines with special provisions for **sensitive health data**
- *"15 Soruda Üretken Yapay Zekâ ve Kişisel Verilerin Korunması Rehberi"* (2024-2025) – Generative AI guidance emphasizing human-centered approaches, transparency, and rights to object to automated decision-making
- *"Yapay Zekâ Teknolojilerine Akademik Bakış"* (Book, 2024) – Contains specific chapters on AI applications for **vulnerable groups** and **healthcare data protection**

These KVKK guidelines directly apply to mental health AI given that psychological data constitutes "special category" sensitive data under Turkish law.

### Academic ethics guidelines address AI in research

**YÖK (Council of Higher Education)** published *"Yükseköğretim Kurumları Bilimsel Araştırma ve Yayın Faaliyetlerinde Üretken Yapay Zekâ Kullanımına Dair Etik Rehber"* (2024), establishing seven principles for AI in academic work: **transparency, honesty, due care, justice/respect, privacy protection, accountability, and contributing to ethical climate**. While targeting research rather than clinical practice, these principles apply to psychology and psychiatry academic publications.

| Document | Issuing Body | Year | Relevance |
|----------|--------------|------|-----------|
| National AI Strategy | Presidential Digital Transformation Office | 2021 (updated 2024) | Healthcare as priority sector; general ethical principles |
| AI Data Protection Recommendations | KVKK | 2021 | Sensitive health data provisions |
| Generative AI Guide | KVKK | 2024-2025 | Human-centered approach; vulnerable population protections |
| Academic AI Ethics Guide | YÖK | 2024 | Research ethics applicable to psychology/psychiatry |
| Public Officials AI Ethics Decision | Ethics Board | September 2024 | Applies to public healthcare workers |
| Draft AI Law | TBMM | June 2024 (pending) | Risk-based approach; high-risk healthcare classification |

---

## Professional associations have working groups but no published guidelines

### Türkiye Psikiyatri Derneği established dedicated AI unit

The Turkish Psychiatric Association has formed **D34 – Psikiyatride Yapay Zeka ve İnsan-makine etkileşimi Çalışma Birimi** (AI and Human-Machine Interaction in Psychiatry Working Unit), coordinated by Prof. Dr. Mehmet Kemal Kuşçu with over 150 registered psychiatrist members. Working unit member Doç. Dr. Alişan Burak Yaşar has publicly stated that AI should be viewed as a "powerful assistant, not a competitor," valuable for reducing administrative burdens, enabling out-of-session patient monitoring, digital phenotyping, and expanding rural access to mental health services.

**However, no formal position paper or ethical guidelines document has been published by this working group as of December 2025.**

### Psychology and counseling associations lack formal AI positions

**Türk Psikologlar Derneği** (Turkish Psychological Association) has no dedicated AI position paper. Individual members have made public statements—Dr. Melis Demircioğlu (Istanbul Branch) stated that AI cannot replace therapists as therapy requires genuine human trust relationships, and AI lacks crisis intervention capacity. The association's 2004 ethics code contains no AI provisions.

**Türk Psikolojik Danışma ve Rehberlik Derneği** (Turkish Psychological Counseling Association) published general ethics codes in 2021 without AI-specific provisions. The organization hosts training for ERAL-NIT 5-17, described as Turkey's first AI-integrated domestic intelligence test, but has issued no formal AI guidance for counselors.

---

## Cultural adaptation considerations emerge from available literature

### Therapeutic relationship centrality distinguishes mental health AI

Turkish literature consistently emphasizes that **therapeutic alliance and empathy represent core concerns** for AI in mental health contexts. Gültekin & Şahin (2024) found professionals predicted mental health would be among the last fields transformed by AI precisely because human connection remains central to therapeutic efficacy. This cultural emphasis on relationship-based healing may require distinct adaptation approaches for AI tools targeting Turkish populations.

### Privacy sensitivities reflect cultural context

KVKK guidelines explicitly address **vulnerable populations** including those with mental health conditions, recognizing heightened privacy concerns. Turkish regulatory emphasis on explicit consent for sensitive health data, combined with cultural factors around mental health stigma, suggests that AI applications must incorporate robust privacy protections exceeding minimum legal requirements to achieve acceptance.

### Professional identity concerns emerge across studies

Multiple Turkish studies reveal concerns about AI replacing human professionals—a finding with particular resonance given mental health workforce challenges. Healthcare workers in Kaplan & Uçar (2024) continued using AI despite expressing replacement concerns, suggesting ambivalence that cultural adaptation strategies must address.

---

## Critical gaps define research priorities

### No large-scale quantitative research on mental health professionals exists

**The most significant gap is the absence of large-scale quantitative surveys specifically examining Turkish psychiatrists, psychologists, psychotherapists, or counselors' AI attitudes, knowledge, and readiness.** The single direct study (Gültekin & Şahin, 2024) involved only 13 participants using qualitative methods. This stands in stark contrast to Turkish nursing literature, where multiple studies with samples exceeding 400 participants have established robust findings.

### Demographic and professional variables remain unexamined for target population

No Turkish study has systematically examined how **demographic factors** (age, gender, education level, experience) or **professional characteristics** (specialty, work setting, technology exposure, patient population) influence AI attitudes among mental health professionals. This gap directly corresponds to the second part of the research question.

### Ethics training and competency assessment are absent

No research examines Turkish mental health professionals' **AI ethics knowledge** or **ethical competency** regarding AI implementation. International literature (Cecil et al., 2025) identifies ethical knowledge as a key predictor of AI adoption intentions among mental health practitioners—a finding urgently requiring Turkish replication.

### Professional guidelines remain undeveloped

Despite the Turkish Psychiatric Association's AI working group, no professional association has published formal guidelines for AI use in mental health practice. This regulatory vacuum means practitioners lack guidance on appropriate implementation, ethical boundaries, and professional responsibilities.

---

## Demographic variables examined in related Turkish healthcare studies

Studies on Turkish nurses and healthcare workers have identified significant attitudinal differences based on:

- **Gender**: Mixed findings—some studies show males with higher AI readiness, others show no difference
- **Education level**: Higher education generally associated with more positive attitudes and greater openness to change
- **Age/experience**: Younger professionals and those with fewer years of experience show higher AI awareness
- **Technology relationship**: Self-reported "good" technology relationships correlate with positive attitudes
- **Work setting**: ICU, surgical, and operating room nurses show higher awareness than other specialties
- **Prior AI exposure**: Previous AI study/use experience predicts positive attitudes
- **Geographic location**: Significant regional variation in attitudes across Turkish provinces

These variables provide a starting framework for examining mental health professionals, though specialty-specific factors (theoretical orientation, patient population, clinical setting) likely require additional consideration.

---

## Conclusion: A research imperative emerges

This review reveals that research on AI attitudes, ethics, and readiness among Turkish mental health professionals represents a **critical gap in the literature**. The single qualitative study available suggests cautious optimism among a small expert sample, while broader Turkish healthcare research indicates generally positive attitudes tempered by ethical concerns about transparency, human relationships, and professional autonomy.

The proposed research question addresses a genuinely underexplored area. Three immediate research priorities emerge: **(1)** large-scale quantitative surveys using validated instruments (GAAIS, Medical AI Readiness Scale) with representative samples of Turkish psychiatrists, psychologists, and counselors; **(2)** examination of AI ethics knowledge and training needs; and **(3)** development of culturally adapted guidelines through professional association engagement. The Turkish Psychiatric Association's D34 Working Group represents an institutional partner for such work. International methodological templates exist—particularly Cecil et al.'s (2025) mixed-methods study of German and American mental health practitioners—that could be adapted for the Turkish context, enabling both local findings and cross-cultural comparison.