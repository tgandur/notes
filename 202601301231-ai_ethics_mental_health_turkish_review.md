---
tags:
title: ai_ethics_mental_health_turkish_review
type: note
permalink: efforts/research/ai-clinical-psychology-ethics/notes/ai-ethics-mental-health-turkish-review
---

# ai_ethics_mental_health_turkish_review
#jots #ai_ethics

Related: [[202512011220-AI Ethics & Mental Health Professionals]]


**Araştırma Sorusu:** Türkiye'de görev yapan ruh sağlığı profesyonellerinin yapay zekâ ve yapay zekâ etiğine ilişkin tutum, bilgi ve klinik kullanımına yönelik hazırbulunuşluk düzeyleri nedir ve bu düzeyler demografik ve mesleki özelliklere göre nasıl farklılaşmaktadır?

**Odak:** Yapay zeka etiği çerçeveleri ve etik kaygılar (mahremiyet, terapötik ilişki, sorumluluk, özerklik, şeffaflık)

**Kapsam:** 2020-2025, Türkçe akademik kaynaklar (TRDizin, DergiPark), ruh sağlığı odaklı

---

## GİRİŞ: ETİK TARTIŞMALARIN KAÇINILMAZLIĞI

Türkçe akademik literatürde yapay zeka ve ruh sağlığı kesişimini ele alan hemen her çalışma, **etik sorunların kaçınılmaz** bir boyut olduğunu vurgular. Gültekin'in (2022) belirttiği gibi, "Yapay zeka kavramı, tüm dünyada 1950'lerden bu yana hem geliştirilen bir teknoloji hem de çeşitli kaygı ve etik tartışmaları barındıran bir konudur" (s. 121). Ancak, bu tartışmalar çoğunlukla **genel etik ilkeler** düzeyinde kalır; ruh sağlığı profesyonellerinin spesifik etik yetkinliklerini, bilgi düzeylerini ve kaygılarını inceleyen ampirik çalışma neredeyse yoktur.

Bu literatür taraması, Türkçe kaynaklarda **ruh sağlığında AI etiğinin nasıl kavramsallaştırıldığını**, hangi etik ilkelerin öne çıktığını ve hangi etik boşlukların bulunduğunu sistematik olarak inceler.

---

## 1. ETİK SORUNLARIN DOĞASI: TEORİK ÇERÇEVELER

### 1.1. Genel Etik İlkeler ve Felsefi Tartışmalar

**Topakkaya ve Eyibaş (2019)** *Felsefe Dünyası*'nda yayınlanan "Yapay Zekâ ve Etik İlişkisi" başlıklı çalışmalarında, YZ etiğinin temel sorunsallarını ele alır: 

> "Yapay zeka doğrudan insanla ve toplumsal yaşamla ilişkili olması bakımından etik çerçevede incelenmelidir. Bugün ve geçmişte insan doğanın ve diğer canlıların varlığının korunmasında her zaman sorumluluk sahibi olmuştur. Bugün de yapay zeka teknolojilerinde etik problemleri göz önünde bulundurmak insanın sorumluluğundadır."

Yazarlar, YZ'nin yaşamımızdaki rolünün artmasının "insan toplumlarını yeni teknolojilerden kaynaklanan tehditlere maruz kalma konusunda endişeye sevk ettiğini" belirtir. Özellikle **algoritmik önyargı**, **adaletsizlik**, **sorumluluk** ve **zarar** konularını ön plana çıkarır.

**Kritik boşluk:** Bu felsefi çalışma ruh sağlığı alanına spesifik değildir; ancak sorumluluk ve önyargı konuları klinik karar verme bağlamında kritik önem taşır.

### 1.2. Sağlık Alanında Etik Çerçeveler

**Güvercin (2020)** "Yapay Zekâ ve Tıp Etiği" başlıklı çalışmasında (Türkiye Klinikleri), sağlıkta YZ kullanımının beş temel etik ilkeye dayandırılması gerektiğini savunur:

1. **Özerklik** (hasta ve klinisyen özerkliğine saygı)
2. **Yararlılık** (faydayı maksimize etme)
3. **Zarar vermeme** (primum non nocere)
4. **Adalet** (eşit erişim ve algoritma adaleti)
5. **Şeffaflık ve açıklanabilirlik**

Ancak, bu ilkeler genel tıbbi bağlamda tartışılır; **ruh sağlığı hizmetlerinin kendine özgü etik dinamikleri**—terapötik ilişki, gizlilik, aktarım-karşı aktarım, kriz yönetimi—ayrıca ele alınmaz.

---

## 2. RUH SAĞLIĞINA ÖZGÜ ETİK SORUNLAR

### 2.1. Terapötik İlişki ve Empatinin Yerine Konulamazlığı

Türkçe literatürde en tutarlı ve tekrarlayan etik kaygı, **YZ'nin empati ve terapötik ittifak kurmadaki yetersizliğidir**.

**Ediboğlu (2023)**, *Çukurova Tıp Öğrenci Dergisi*'ndeki derleme makalesinde "Yapay Zekanın İnsan Zekasına Psikoterapötik Yaklaşımı" başlığıyla konuyu ele alır. Yazar, YZ tabanlı sistemlerin insana benzer empati ve duygusal anlayışa sahip olmadığını açıkça belirtir:

> "YZ tabanlı sistemlerin, insana benzer empati ve duygusal anlayışa sahip olmadığı unutulmamalıdır."

Ediboğlu, **terapötik ilişkinin özünün** anlık duygusal rezonans, sezgi ve "burada ve şimdi"deki varoluşsal karşılaşma olduğunu vurgular. YZ'nin algoritmik tepkileri bu deneyimi taklit edebilir, ancak otantik empatiyi sağlayamaz.

**Gültekin ve Şahin (2024)**, 13 ruh sağlığı profesyoneli ile yaptıkları görüşmelerde katılımcıların **"terapötik ittifak kuramamayı"** YZ'nin en büyük sınırlılığı olarak gördüklerini bulmuştur. Katılımcılar, ruh sağlığının **"en son etkilenecek alanlardan biri"** olacağını öngördü—çünkü insan ilişkisi terapötik değişimin merkezindedir.

**Konyalı ve arkadaşları (2024)** "Psikolojide Yapay Zekâ Kullanımı ve Uygulamaları" çalışmasında şunu ifade eder:

> "Bir terapistin gösterebileceği derin empati, sıcaklık ve sezgi gibi unsurlar, YZ tabanlı terapilerde tam olarak karşılanamaz."

**Etik çıkarım:** YZ'nin klinik kullanımı, **ikame değil tamamlayıcı** olarak konumlandırılmalıdır. Tam otonom YZ terapistleri, terapötik ilişkinin doğasını temelden bozar—bu hem etik hem de klinik bir sorun teşkil eder.

### 2.2. Mahremiyet ve Kişisel Verilerin Korunması

**KVKK (Kişisel Verilerin Korunması Kurumu)**, YZ uygulamalarında **özel kategorili kişisel veriler**—ki ruh sağlığı verileri bunların en hassasıdır—için sıkı düzenlemeler getirmiştir:

- **"Yapay Zekâ Alanında Kişisel Verilerin Korunmasına Dair Tavsiyeler" (2021)**: Sağlık verilerinin işlenmesinde açık rıza, veri minimizasyonu, şeffaflık ve güvenlik önlemlerinin kritik olduğunu vurgular.

- **"Üretken Yapay Zekâ ve Kişisel Verilerin Korunması Rehberi" (2024-2025)**: Üretken yapay zeka modellerinin (örn. ChatGPT benzeri) sağlık verilerini nasıl işlediğine dair spesifik rehberlik sunar; hasta verilerinin eğitim setlerine karışmaması gerektiğini belirtir.

Ancak, Türkçe literatürde **ruh sağlığı bağlamında KVKK uygulamalarını inceleyen ampirik çalışma yoktur**. Profesyoneller KVKK gerekliliklerini ne ölçüde biliyor? AI araçları kullanırken hasta rızasını nasıl alıyorlar? Bu sorular yanıtsız kalıyor.

**Ülker ve Akkan (2023)**, "Ruh Sağlığı Hizmetlerinde Yapay Zeka Uygulamaları ve İlişkili Teknolojiler" çalışmasında dijital fenotipleme ve akıllı telefon izleme sistemlerinin **gizlilik endişeleri** yarattığını not eder, ancak bu endişeleri nasıl yöneteceğine dair klinik protokol önermez.

**Konyalı ve arkadaşları (2024)**:

> "Verilerin paylaşımının nasıl olacağı net değildir. YZ sistemlerinin geliştirilmesinde etik ilkelerin ve toplumsal değerlerin gözetilmesi, şeffaflığın sağlanması ve denetim mekanizmalarının oluşturulması büyük önem taşımaktadır."

**Etik çıkarım:** Mahremiyet **tanımlanmış ancak operasyonelleştirilmemiş** bir kaygıdır. Profesyonellerin KVKK uyumluluğu ve hasta rızası yönetimi konusunda eğitim ihtiyacı açıktır.

### 2.3. Sorumluluk ve Hukuki Açıklık Eksikliği

**Öztürk ve arkadaşları (2025)**, *Psikiyatride Güncel Yaklaşımlar*'da yayınlanan "Artificial Intelligence in Mental Health Practices: Legal Liability Analysis under Turkish, European, and Common Law Frameworks" çalışmasında kritik bir boşluğu vurgular:

> "Yapay zekânın sahip olduğu avantajlar ve uzmanlık faaliyeti olarak yürütülen teşhis ve tedavi hizmetlerinde yapay zekâya yer verilmesi hukuk kurallarının uygulanmasını hiçbir şekilde muaf kılmamaktadır. Yapay zekânın hukukî açıdan bizzat sorumlu olup olamayacağı veyahut da yapay zekâ teknolojilerinin kullanılması sebebiyle sorumluluğun temellendirilmesinin neye göre tayin edileceği sorunu ortaya çıkmaktadır."

Çalışma, **Türk hukuku**, **Avrupa hukuku** ve **Common Law** çerçevelerinde YZ'nin hukuki statüsünü analiz eder. Temel bulgular:

- **YZ tüzel kişilik değildir**, dolayısıyla doğrudan sorumlu tutulamaz
- **Sorumluluk** geliştiricilere, sağlayıcılara ve kullanıcılara (klinisyenlere) dağılır
- **Türk malpraktis hukuku** YZ kullanımını henüz netleştirmemiştir

**Ediboğlu (2023)**:

> "Hatalı teşhis veya yanlış yorumlama durumunda sorumluluk konusu endişe yaratır."

**Etik çıkarım:** **Sorumluluk belirsizliği** klinisyenleri savunmasız bırakır. YZ tavsiyesini takip eden bir psikiyatrist, hasta zarar görürse kim sorumludur? Bu belirsizlik, AI benimsemesini engelleyen bir etik kaygıdır.

### 2.4. Algoritmik Önyargı ve Adalet

**Akgöz ve arkadaşları (2022)**, "Günümüz ve Gelecekteki Teknolojinin Psikoterapi Uygulamalarına Etkisi ve Etik Tartışmalar" başlıklı çalışmalarında algoritmik önyargının **kültürel bağlamda** nasıl tezahür edebileceğini tartışır:

- YZ modelleri genellikle **WEIRD (Western, Educated, Industrialized, Rich, Democratic) popülasyonlarda** eğitilir
- Türk kültürel normları, ifade tarzları ve psikolojik yapılar farklıdır
- **Kültürel adaptasyon olmadan** YZ tanı/tedavi araçları yanıltıcı olabilir

**Konyalı ve arkadaşları (2024)**:

> "Algoritmalar, önyargı gibi konular açısından incelenmeli ve tartışmaya açık olmalıdır."

Ancak, **Türkiye'de YZ ruh sağlığı araçlarının kültürel geçerliliğini test eden çalışma bulunmamıştır**. Bu ciddi bir etik ve bilimsel boşluktur.

### 2.5. Şeffaflık ve "Kara Kutu" Problemi

**Gültekin ve Şahin (2024)**, profesyonellerin **"kara kutu" endişesi** taşıdığını—YZ'nin nasıl kararlara vardığını anlayamadıklarını—bulmuştur. Katılımcılar, algoritmik karar vermenin opaklığının **güven eksikliğine** yol açtığını ifade etmiştir.

**Ediboğlu (2023)**:

> "Yapay zeka, zarar bildirme ve bakım sorumluluğunu yerine getirmek için denetim altında olmalı ve şeffaf bir şekilde kullanılmalıdır."

**Açıklanabilir AI (Explainable AI)** kavramı Türkçe literatürde tartışılır (Miller, 2019'dan aktarılan), ancak **klinik uygulamada nasıl sağlanacağı belirsizdir**.

**Etik çıkarım:** Klinisyenler, anlamadıkları bir sistemin önerilerine dayanarak tedavi kararları alamazlar—bu hem etik (informed consent) hem de hukuki (due diligence) bir yükümlülüktür.

### 2.6. Özerklik ve Paternalizm Riski

YZ sistemleri, klinisyenin kararlarını "override" ederse veya hasta tercihleri yerine algoritmik önerileri önceliklendirirse, **hasta özerkliğine** ve **klinisyen profesyonel yargısına** saygı tehlikeye girer.

**Güvercin (2020)**, otonom karar verme sistemlerinin hekim özerkliğini sınırlayabileceğini, "algoritmik paternalizm" riski yaratabileceğini uyarır.

Ancak, **ruh sağlığı bağlamında özerklik özellikle hassastır**:
- **Kapasite sorunları**: Psikotik, manik veya ağır depresif hastalarda karar verme kapasitesi bozulabilir
- **İstemli tedavi**: YZ, istemsiz yatış kararlarında kullanılırsa, özgürlük kısıtlaması etik boyutu artırır

Türkçe literatürde bu boyut **tartışılmamıştır**.

---

## 3. ÖZGÜL UYGULAMALARDA ETİK SORUNLAR

### 3.1. Dijital Fenotipleme ve İzleme: Gözetim Endişeleri

**Ülker ve Akkan (2023)**, dijital fenotiplemenin (GPS, akıllı telefon kullanımı, sosyal medya aktivitesi) ruh sağlığı izlemesindeki potansiyelini tartışırken, **sürekli gözetim**in hastalar üzerinde baskı yaratma riskini not eder.

**Etik sorun:** Hasta ne zaman "izlendiğini" biliyor? Rıza tek seferlik mi, yoksa sürekli mi? İzin geri çekilebilir mi? Bu sorular yanıtsızdır.

### 3.2. Sohbet Botları ve Sanal Terapistler: Aldatıcı Müdahale

**Ediboğlu (2023)**, ELIZA ve Woebot gibi sohbet botlarını inceler. Önemli bir etik sorunsalı vurgular:

Borbolla'nın Anthenos karakteri örneğinde:

> "Fakat dürüstlük ilkesi göz ardı ediliyor gibi durmaktadır. Çocuk aslında bir yetişkinle görüşmektedir ama bunu bilmiyordur ve belki de öğrenmek hayal kırıklığı oluşturacaktır."

**Etik çıkarım:** **Aldatıcı müdahale** (deceptive intervention) kabul edilemez. Hastalar YZ ile mi, insan terapistle mi konuştuklarını **bilmelidirler**. Şeffaflık, informed consent'in temelidir.

### 3.3. Avatar Terapisi ve VR: Kimlik Kargaşası Riski

**Ediboğlu (2023)**, avatar terapisinde hastaların sanal karakterlerle etkileşime girdiğini, ancak bunun **kimlik sınırlarını bulanıklaştırma** riski taşıdığını tartışır—özellikle psikotik bozukluklarda.

Bu uygulama bazı çalışmalarda etkili bulunmuş (Du Sert et al., 2018), ancak **uzun vadeli etik etkiler** incelenmemiştir.

---

## 4. ETİK İLKELER VE ÖNERİLER: SİSTEMATİK YAKLAŞIM

### 4.1. Ediboğlu'nun (2023) Etik Öneri Çerçevesi

Ediboğlu, YZ'nin ruh sağlığında kullanımı için kapsamlı etik öneriler sunar:

1. **Standart değerlendirme**: YZ uygulamaları sağlık teknolojisi değerlendirmesine (HTA) tabi tutulmalı
2. **Düzenleyici onay**: Net rehberlik geliştirilmeli
3. **Mesleki yönergeler**: Türk Psikiyatri Derneği, Türk Psikologlar Derneği gibi kurumlar AI kullanım kılavuzları yayınlamalı
4. **Eğitim**: Ruh sağlığı profesyonelleri YZ etiği konusunda eğitilmeli
5. **Tamamlayıcı rol**: YZ ek kaynak olmalı, insan uzmanların sorumluluğunu azaltmamalı
6. **Denetim ve şeffaflık**: Algoritmalar önyargı açısından incelenmeli
7. **Uzun vadeli araştırma**: Etkileri ve sonuçları izleyen çalışmalar gerekli

### 4.2. YÖK (2024) Akademik Etik İlkeleri

**YÖK Üretken Yapay Zekâ Etik Rehberi**, akademik bağlamda yedi ilke belirler:

1. **Şeffaflık**
2. **Dürüstlük**
3. **Özen**
4. **Adalet ve saygı**
5. **Mahremiyet koruması**
6. **Sorumluluk**
7. **Etik iklim oluşturma**

Bu ilkeler, **klinik araştırma ve eğitimde** AI kullanımına uygulanabilir, ancak doğrudan klinik pratik için değildir.

---

## 5. KRİTİK BOŞLUKLAR VE ARAŞTIRMA ÖNCELİKLERİ

### 5.1. Ampirik Etik Araştırmaların Yokluğu

Türkçe literatürde **ruh sağlığı profesyonellerinin etik bilgi, farkındalık ve yetkinliklerini** ölçen çalışma **bulunmamaktadır**. Şu sorular yanıtsızdır:

- Profesyoneller KVKK gerekliliklerini biliyor mu?
- Algoritmik önyargıyı tanıyabiliyorlar mı?
- Informed consent süreçlerini AI bağlamında nasıl yönetiyorlar?
- Etik ikilemlerde (örn. YZ önerisi vs. klinik yargı) nasıl karar veriyorlar?

### 5.2. Klinik Protokol ve Kılavuz Eksikliği

**Türk Psikiyatri Derneği D34 Çalışma Birimi** var, ancak **yayınlanmış kılavuz yok**. Profesyoneller şu konularda rehbersiz:

- Hangi durumlarda AI kullanımı etiktir?
- Hasta rızası nasıl alınmalı?
- AI hatası durumunda ne yapılmalı?
- Kültürel olarak uygun AI araçları nasıl seçilir?

### 5.3. Kültürel Adaptasyon Araştırmalarının Yokluğu

**Türk popülasyonunda YZ araçlarının geçerliliği** test edilmemiştir. Bu hem bilimsel hem de etik sorumluluk eksikliğidir—etkisiz veya zararlı araçlar kullanılıyor olabilir.

### 5.4. Hasta Perspektifi Araştırmalarının Eksikliği

**Aktan, Turhan ve Dolu (2022)** genel halkı incelemiş, ancak **ruh sağlığı hastalarının** AI kullanımına dair görüşleri, kaygıları ve tercihleri **bilinmiyor**. Etik olarak, hasta sesi merkezi olmalıdır.

---

## 6. SONUÇ VE ARAŞTIRMA ÖNERİLERİ

### 6.1. Türkçe Literatürün Profili

Türkçe literatür, **AI etiğini tanımlar ancak operasyonelleştirmez**. Etik ilkeler belirtilir (mahremiyet, şeffaflık, özerklik), ancak:

- **Nasıl sağlanacakları** netleştirilmemiştir
- **Klinik uygulama protokolleri** yoktur
- **Profesyonellerin etik yeterlilikleri** ölçülmemiştir
- **Hasta perspektifleri** ihmal edilmiştir

### 6.2. Araştırma Sorunuza Doğrudan Bağlantı

Araştırma sorunuz—**"Türkiye'de ruh sağlığı profesyonellerinin AI etiğine ilişkin bilgi ve hazırbulunuşluk düzeyleri"**—literatürdeki en kritik boşluğu hedeflemektedir.

**Önerilen araştırma bileşenleri:**

1. **Etik bilgi ölçümü**: KVKK bilgisi, algoritmik önyargı farkındalığı, sorumluluk anlayışı
2. **Etik tutumlar**: Şeffaflık önemine verilen değer, hasta özerkliğine saygı, mahremiyet hassasiyeti
3. **Etik uygulamalar**: Informed consent süreçleri, YZ hata yönetimi, kültürel uygunluk değerlendirmesi
4. **Etik eğitim ihtiyacı**: Ne öğrenmek istiyorlar, hangi konularda kendilerini yetersiz hissediyorlar?

### 6.3. Metodolojik Öneriler

**Nicel boyut:**
- **AI Ethics Knowledge Scale** (yeni geliştir veya adapte et)
- **Ethical Concerns about AI in Mental Health** (kaygı envanterleri)
- **KVKK Awareness Questionnaire**

**Nitel boyut (Gültekin & Şahin 2024'ü genişlet):**
- Etik ikilemlere dair vinyetler
- "Ne yapardınız?" senaryoları
- Odak grup tartışmaları

**Demografik değişkenler:**
- Yaş/cinsiyet/deneyim (genel)
- **Etik eğitim geçmişi** (hiç aldı mı?)
- **AI kullanım deneyimi** (kullananlar vs. kullanmayanlar)
- **Teorik oryantasyon** (bilişsel-davranışçı, psikanalitik, vb.)
- **Çalışma ortamı** (kamu vs. özel, bireysel vs. ekip)

### 6.4. Politika ve Uygulama Önerileri

1. **Dernek kılavuzları**: TPD ve TPD acilen AI etik kılavuzları yayınlamalı
2. **Müfredat entegrasyonu**: Mezuniyet öncesi ve sonrası AI etiği eğitimi
3. **KVKK uyum protokolleri**: Ruh sağlığı kurumları için spesifik rehberlik
4. **Hasta bilgilendirme materyalleri**: AI kullanımı hakkında standart formlar
5. **Etik danışma mekanizmaları**: Klinisyenler için AI etiği sorusu danışma hattı

---

## KAYNAKÇA

### Doğrudan Ruh Sağlığı ve AI Etiği Çalışmaları

**Ediboğlu, G.O. (2023)**. Yapay zekanın insan zekasına psikoterapötik yaklaşımı. *Çukurova Tıp Öğrenci Dergisi*, 3(1), 12-18.
- **Odak**: Etik ve güvenlik konuları, terapötik ilişki, sorumluluk
- **Önemli bulgular**: YZ empati kuramaz; dürüstlük ilkesi ihlali riski; sorumluluk belirsizliği
- **DOI**: Belirtilmemiş
- **Erişim**: https://dergipark.org.tr/tr/pub/cukurovatip/issue/78489/1314136

**Gültekin, M. (2022)**. Yapay zekanın ruh sağlığı hizmetlerinde kullanımına ilişkin fırsatlar ve sorunlar. *İnsan ve Toplum*, 12(3), 121-158.
- **Odak**: Kapsamlı derleme, avantajlar ve dezavantajlar, etik/hukuki kaygılar
- **Önemli bulgular**: Empati sınırlılığı, ayrımcılık riskleri, maliyet düşüşü
- **DOI**: 10.12658/M0664
- **Erişim**: DergiPark

**Gültekin, M. & Şahin, M. (2024)**. The use of artificial intelligence in mental health services in Turkey: What do mental health professionals think? *Cyberpsychology: Journal of Psychosocial Research on Cyberspace*, 18(1), Article 6.
- **Odak**: Nitel çalışma, 13 profesyonel, tutumlar ve etik kaygılar
- **Önemli bulgular**: Terapötik ittifak kuramamak; etik farkındalık düşük; sorumluluk endişesi
- **DOI**: 10.5817/CP2024-1-6
- **Erişim**: https://cyberpsychology.eu/article/view/21522

**Konyalı, A., Naipoğlu, C., Güner, S., Bakkal, İ., & Çelik, A.R. (2024)**. Psikolojide yapay zekâ kullanımı ve uygulamaları. *Journal of Kocaeli Health and Technology University*, 3(1).
- **Odak**: YZ'nin psikoloji uygulamaları, etik sorunlar
- **Önemli bulgular**: Veri paylaşımı belirsiz; etik ilkeler ve şeffaflık gerekli; denetim mekanizmaları eksik
- **Erişim**: https://dergipark.org.tr/tr/pub/jokohtu/issue/91492/1641864

**Ülker, S.V. & Akkan, G. (2023)**. Ruh sağlığı hizmetlerinde yapay zeka uygulamaları ve ilişkili teknolojiler. *Fenerbahçe Üniversitesi Sosyal Bilimler Dergisi*, 3, 242-263.
- **Odak**: Dijital fenotipleme, sanal terapistler, VR, mobil uygulamalar
- **Önemli bulgular**: Mahremiyet endişeleri; gözetim riski
- **Erişim**: https://dergipark.org.tr/tr/pub/fbujoss/issue/82142/1368922

**Akgöz, N., Ülker, S.V., Keskin, R., & Arasan Doğan, İ. (2022)**. Günümüz ve gelecekteki teknolojinin psikoterapi uygulamalarına etkisi ve etik tartışmalar. *International Journal of Social, Humanities and Administrative Sciences (JOSHAS)*, 8(59), 1840-1848.
- **Odak**: Teknolojinin psikoterapi üzerindeki etkisi, etik tartışmalar
- **Önemli bulgular**: Kültürel adaptasyon gerekli; algoritmik önyargı riski

**Turan, B., Gülşen, M., & Yılmaz, A.E. (2022)**. Psikiyatrik bozukluklarda yapay zeka uygulamaları. *Ankara Üniversitesi Tıp Fakültesi Mecmuası*, 75(1), 56-62.
- **Odak**: Psikiyatrik bozukluklarda AI uygulamaları, sınırlamalar
- **DOI**: 10.4274/atfm.galenos.2022.36002
- **TR Dizin**: Evet

**Öztürk, R., Öztürk, A., & Yılmaz, K. (2025)**. Artificial intelligence in mental health practices: Legal liability analysis under Turkish, European, and Common Law frameworks. *Psikiyatride Güncel Yaklaşımlar*, (baskıda).
- **Odak**: Hukuki sorumluluk analizi
- **Önemli bulgular**: YZ tüzel kişilik değil; sorumluluk belirsizliği; malpraktis hukuku yetersiz
- **Erişim**: https://dergipark.org.tr/en/pub/pgy/issue/90362/1620119

### Genel Etik Çalışmaları

**Topakkaya, A. & Eyibaş, Y. (2019)**. Yapay zekâ ve etik ilişkisi. *Felsefe Dünyası*, 70, 81-99.
- **Odak**: Felsefi etik tartışmalar, sorumluluk, önyargı, zarar
- **Erişim**: https://dergipark.org.tr/en/pub/felsefedunyasi/issue/58339/850694

**Güvercin, C.H. (2020)**. Yapay zekâ ve tıp etiği. *Türkiye Klinikleri*, 1, 7-13.
- **Odak**: Sağlıkta AI için temel etik ilkeler (özerklik, yararlılık, zarar vermeme, adalet, şeffaflık)

### Düzenleyici ve Kurumsal Belgeler

**KVKK (2021)**. Yapay zekâ alanında kişisel verilerin korunmasına dair tavsiyeler.
- **Önemli içerik**: Sağlık verisi hassasiyeti, açık rıza, veri minimizasyonu

**KVKK (2024-2025)**. Üretken yapay zekâ ve kişisel verilerin korunması rehberi.
- **Önemli içerik**: Üretken AI'da sağlık verisi yönetimi, hasta haklarına saygı

**YÖK (2024)**. Yükseköğretim kurumları bilimsel araştırma ve yayın faaliyetlerinde üretken yapay zekâ kullanımına dair etik rehber.
- **Önemli içerik**: Yedi etik ilke (şeffaflık, dürüstlük, özen, adalet, mahremiyet, sorumluluk, etik iklim)
- **Erişim**: https://www.aa.com.tr/tr/egitim/yokten-uretken-yapay-zeka-kullanimina-dair-etik-rehber/3212359

**Türkiye Cumhuriyeti Cumhurbaşkanlığı (2021, güncelleme 2024)**. Ulusal Yapay Zekâ Stratejisi 2021-2025.
- **Önemli içerik**: Sağlık öncelikli sektör; etik ilkeler (şeffaflık, sorumluluk, güvenlik, adalet, mahremiyet, insan gözetimi)
- **Erişim**: https://regulations.ai/regulations/turkey-ai-strategy-2021-2025

### İlgili Ampirik Çalışmalar

**Aktan, M.E., Turhan, Z., & Dolu, İ. (2022)**. Attitudes and perspectives towards the preferences for artificial intelligence in psychotherapy. *Computers in Human Behavior*, 133, Article 107273.
- **Odak**: Genel halk (N=872), AI bazlı psikoterapi tercihleri
- **Önemli bulgular**: %55 pozitif algı; meslek grubu farkları; AI deneyimi etkili
- **DOI**: 10.1016/j.chb.2022.107273
- **Not**: Türkiye örneklemi, ancak uluslararası dergi

---

## EK NOTLAR

### Kaynakların Sınırlılıkları

1. **Ampirik veri eksikliği**: Çoğu çalışma teorik/derleme türündedir
2. **Metodolojik zayıflık**: Gültekin & Şahin (2024) hariç, ruh sağlığı profesyonelleriyle doğrudan ampirik çalışma yok
3. **Kültürel adaptasyon yokluğu**: Hiçbir çalışma Türk kültüründe AI araç geçerliliğini test etmemiş
4. **Hasta perspektifi ihmal**: Sadece bir çalışma (Aktan et al., 2022) hasta/kullanıcı görüşlerini almış

### Araştırma İçin Pratik Öneriler

**Anket madde örnekleri:**

*Etik bilgi:*
- "KVKK'ya göre, hastanın ruh sağlığı verileri için özel kategorili veri koruması gerekir." (Doğru/Yanlış)
- "Algoritmik önyargı, AI sistemlerinin belirli grupları sistematik olarak yanlış değerlendirmesi anlamına gelir." (Doğru/Yanlış)

*Etik tutumlar:*
- "AI sistemleri karar süreçlerini şeffaf bir şekilde açıklamalıdır." (1-5 Likert)
- "Hasta, AI kullanıldığını bilmelidir." (1-5 Likert)

*Etik uygulamalar:*
- "AI kullanırken hastadan yazılı onam alır mısınız?" (Evet/Hayır/Bazen)
- "AI önerisi klinik yargınızla çelişirse ne yaparsınız?" (Açık uçlu)

---

**SON SÖZ:** Bu literatür taraması, Türkiye'de ruh sağlığında AI etiğinin **konseptüel olarak tanımlandığını ancak ampirik olarak incelenmediğini** göstermektedir. Araştırma sorunuz bu kritik boşluğu doldurmaya yöneliktir ve hem bilimsel hem de klinik öneme sahiptir.