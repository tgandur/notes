---
title: >-
 Mental health practitioners' perceptions and adoption intentions of AI-enabled
 technologies an international mixed-methods study
authors: Julia Cecil, Anne-Kathrin Kleine, Eva Lermer, Susanne Gaube
year: 2025
source: BMC Health Services Research
doi: 10.1186/s12913-025-12715-8
tags:
 - mixed-methods-study
 - practitioner-perceptions
 - ai-readiness
 - ai-mental-health
 - adoption-intentions
 - training-needs
type: source
status: reviewed
added: 2024-12-13T00:00:00.000Z
relevance: high
---

# Cecil 2025 - MH Practitioners AI Perceptions
#lit #ai_ethics

Related: [[202512011220-AI Ethics & Mental Health Professionals]]


## Key Findings

1. **Major Familiarity Gap**: 45.4% of practitioners had NEVER heard of AI-enabled technologies in mental healthcare; only 9.7% actively researched the topic; 93.37% have NOT used AI in clinical practice

2. **Limited Understanding**: When asked to describe AI in mental health, 10.5% couldn't provide any description; 53.7% mentioned only one application area; only 0.6% (2 participants) could name all four application areas

3. **Learning > Use Intentions**: Practitioners significantly more willing to LEARN about AI (M=3.65) than actually USE it (M=3.14), indicating theoretical interest but practical hesitation

4. **Application Area Preferences**:
 - Highest learning intention: Practice management tools (M=3.91)
 - Highest use intention: Practice management (M=3.70)
 - Lowest intentions: Patient-centered tools (diagnostics, treatment) vs. clinician-centered tools (feedback, admin)

5. **Key Adoption Predictors Across ALL Areas**:
 - Learning intention positively predicts use intention
 - Ethical knowledge/readiness crucial for use intentions
 - Affinity for technology interaction consistently predicts use
 - Professional identification drives learning (except for admin tasks)

6. **Profession Differences**: Psychiatrists showed significantly higher learning and use intentions than psychotherapists and clinical psychologists

7. **Training Deficit**: <10% received formal training on AI; most learned from mainstream media (social media, news) rather than structured education

## Methodology

**Design:** Pre-registered cross-sectional mixed-methods survey (qualitative + quantitative SEM modeling)

**Sample:** N = 392 mental health practitioners from Germany (n=236) and US (n=156)
- 60% psychotherapists in training
- 18.6% psychotherapists
- 9.9% psychiatrists
- 10.7% clinical psychologists
- 74.2% female, 23.5% male
- Mean age: 34.34 years (SD=10.46)
- Mean professional experience: 5.89 years (SD=7.26)
- Diverse therapeutic approaches: 56.8% CBT, 19.3% psychodynamic, 6% psychoanalytic, 6.2% systemic

**Data Collection:**
- July-October 2023
- Online survey (German and English versions)
- Four AI application areas examined separately: (1) Diagnostics, (2) Treatment support, (3) Feedback for practitioners, (4) Practice management
- **Qualitative**: Open-ended questions on understanding, familiarity, learning context
- **Quantitative**: SEM modeling with predictor variables based on COM-B model (Capability-Opportunity-Motivation-Behavior)
- Measured: Learning intention, use intention, AI readiness (cognitive/vision/ethical), AI anxiety (learning/job replacement/sociotechnical blindness), technology self-efficacy, affinity for technology, professional identification

**Analysis:**
- Deductive thematic analysis for qualitative data
- Structural equation modeling (SEM) for each application area
- Group comparisons (profession, gender, country)

## Relevance to My Research

**Why it matters:**
Most comprehensive empirical study to date on MHP attitudes toward AI across multiple professions, countries, and application areas. Uses robust theoretical framework (COM-B) and rigorous methodology (pre-registered, SEM). Identifies specific barriers and facilitators for different types of AI tools. Critical for understanding what drives or hinders AI adoption among MHPs.

**Turkish context:**
- International sample (Germany/US) provides comparison framework for Turkish study
- Reveals universal challenges: familiarity gaps, training deficits, ethical concerns
- Shows profession-specific differences (psychiatrists vs psychologists) - highly relevant for Turkish context where both groups practice
- Identifies modifiable factors (training, ethical education) applicable to Turkish implementation
- Demonstrates need for tailored approaches by application area - Turkish developers/policymakers need similar nuance
- Highlights role of professional identity - culturally salient in Turkey

## Important Quotes

> "Nearly half of the practitioners (n = 178, 45.4%) stated that they have never heard of AI-enabled technologies in the field of psychotherapy/psychiatry" (p. 9)

> "The vast majority of participating practitioners (n = 366, 93.37%) have not used AI-enabled technologies in their clinical practice" (p. 9)

> "Only one-tenth of practitioners who had heard about AI technologies received formal education on the topic" (p. 12)

> "Current training programs may not adequately cover AI-related topics, thereby limiting practitioners' exposure and understanding. As a lack of training and instructions on technology use in healthcare further contributes to an unsafe work environment and medical errors, the results underline the need of adjusting the training to emerging technologies." (p. 12)

> "Practitioners were more inclined towards learning rather than actively using AI-enabled technologies in their clinical practice" (p. 12)

> "Participants demonstrated different levels of willingness to engage with AI-enabled technologies across the application areas. Notably, they were less hesitant towards clinician-centered feedback or practice management tools compared to patient-centered tools" (p. 12-13)

> "Ethical readiness emerged as a significant predictor for use intentions across all application areas, making it a driving force for the intention to use AI-enabled technologies in healthcare" (p. 13)

> "Half of the practitioners have not heard about AI-enabled technology in mental healthcare demonstrates the need for formal education on this topic" (p. 14-15)

## Limitations

**Study limitations:**
- Cross-sectional design prevents causal inferences
- Brief open-ended responses may not capture full understanding
- Data collected in late 2023 - rapid AI development may outpace findings
- No balancing of application area presentation order
- No direct hands-on interaction with AI technologies
- Suppression effects in some models complicate interpretation
- Only Germany and US - limited geographic diversity

**What's missing for my research:**
- No Turkish, Middle Eastern, or non-Western developing country perspectives
- Limited cultural analysis despite international sample
- No examination of cultural values affecting attitudes
- Insufficient exploration of barriers specific to non-Western contexts
- No data on resource-constrained healthcare settings
- Missing: policy/regulatory environment effects
- No patient perspectives included

## My Notes

### Professional Attitudes - Nuanced by Profession

**Psychiatrists vs Psychologists/Psychotherapists:**
- Psychiatrists: Higher learning AND use intentions across all areas
- Reason: Medical training includes more tech exposure, closer to broader medical field where AI more prevalent, prescription tasks align with AI applications
- Psychologists/Psychotherapists: More hesitant, especially re: patient-centered tools
- Reason: Practice centered on interpersonal relationships, view tech as potential substitute for human care

**Overall Pattern:**
- Theoretical interest (learning) exceeds practical commitment (use)
- More comfortable with tools that support their work (admin, feedback) than replace clinical judgment (diagnosis, treatment)
- Strong preference for clinician-centered over patient-centered applications

### Ethical Concerns (Central Finding!)

**Ethical Knowledge = Key Predictor:**
- Ethical readiness ONLY consistent predictor of use intentions across ALL four application areas
- Suggests ethics is gateway to adoption - practitioners won't use tools they can't ethically justify
- Reflects high value of ethics in mental health (emotional relationships, sensitive information)

**Ethical Components:**
- Awareness of ethical standards
- Knowledge of guidelines
- Adherence to ethical principles
- Concerns about transparency, privacy, patient safety, informed consent

**Implications:**
- Training must prioritize ethics education
- Developers should transparently display compliance with ethical/legal norms (MDR, AIA)
- Ethics not just barrier but potential facilitator if addressed properly

### Barriers to Adoption

**Knowledge/Understanding Barriers:**
- 45% never heard of AI in mental health
- Limited understanding even among aware practitioners
- Most knowledge from media, not formal education
- Lack of training identified as major barrier
- Complex, opaque nature of ML algorithms increases resistance

**Psychological Barriers:**
- Higher stakes for patient-centered vs clinician-centered tools
- Fear of errors with diagnostic/treatment tools (severe consequences)
- Concerns about transparency, privacy, cybersecurity
- Need for informed consent creates hesitation
- Professional identity concerns (for some)

**Contextual Barriers:**
- Training programs don't cover AI topics adequately
- Lack of formal education opportunities
- No hands-on experience with tools
- Rapid pace of development outpaces knowledge

**NOT Barriers (Surprising):**
- Job replacement anxiety NOT significant predictor (only moderate levels reported)
- Only 4% believe AI will make jobs obsolete
- General AI anxiety not as important as expected when examining subdimensions

### Training Needs - Specific & Actionable

**Formal Education Gaps:**
- <10% received formal training
- Majority (60%) are trainees - programs failing to integrate AI content
- Need curriculum integration at training level

**Content Needs (Evidence-Based from Predictors):**
1. **Ethics Education** (highest priority) - ethical standards, guidelines, responsible use
2. **Hands-On/Practical Experience** - foster affinity, comfort with technology interaction
3. **Basic AI Literacy** (cognitive readiness) - understanding mechanisms, strengths/weaknesses
4. **Vision Development** - anticipating impact, envisioning applications
5. **Human Oversight Skills** - monitoring AI decisions, ensuring proper supervision

**Delivery Methods:**
- Integrate into curricula and professional development
- On-the-job training for practical skills
- Interactive demonstrations of AI technologies
- Application-area specific training (diagnostics ≠ admin)

### Cultural Factors

**Limited Cultural Analysis Despite International Sample:**
- Germany vs US comparison opportunity largely unexploited
- Cultural values affecting attitudes not explored
- Profession differences may reflect cultural training models
- Professional identity (positive predictor) - culturally shaped construct

**Potential Cultural Considerations:**
- German context: Stricter data privacy regulations (GDPR), more cautious approach
- US context: More tech adoption, less regulatory caution
- Both Western, high-resource countries - findings may not generalize globally

### Four Application Areas - Differentiated Findings

**1. Diagnostics (Patient-Centered)**
- LOW use intention (M=2.78 - lowest)
- Practitioners most hesitant
- High stakes: wrong diagnosis = wrong treatment, poor prognosis
- Most familiar area mentioned (43.4%)

**2. Treatment Support (Patient-Centered)**
- MODERATE use intention (M=2.96)
- Most frequently mentioned area (69.8%)
- More familiar but still patient-facing = higher stakes
- Vision readiness predicts learning (practitioners with advanced understanding want to deepen knowledge)

**3. Feedback for Practitioners (Clinician-Centered)**
- MODERATE use intention (M=3.13)
- LEAST mentioned area (only 1.7% - 6 participants!)
- Cognitive readiness predicts learning (basic knowledge drives exploration of unfamiliar tools)
- Lower stakes than patient-centered

**4. Practice Management (Clinician-Centered)**
- HIGHEST learning (M=3.91) and use intentions (M=3.70)
- Frequently mentioned (41.1%)
- Administrative burden reduction highly valued
- Lower stakes, indirect patient impact
- Professional identification NOT predictor (admin not core to identity)

### Theoretical Framework: COM-B Model

**Capability Factors:**
- Cognitive readiness: Positively associated with learning feedback tools
- Vision readiness: Positively associated with learning treatment tools
- Ethical readiness: ROBUST predictor of use across ALL areas

**Motivation Factors:**
- Reflective: Technology self-efficacy (complex suppression effects), Affinity for technology (strong positive predictor of use across all areas), Professional identification (predicts learning for patient-centered tools + feedback)
- Automatic: AI anxiety subdimensions show nuanced effects - moderate sociotechnical blindness can increase learning motivation for treatment and practice management tools

**Opportunity Factors:**
- Not directly measured (external to individual)
- Implied: lack of training opportunities, no formal education

**Model Value:**
- Provides comprehensive framework
- Identifies modifiable vs fixed factors
- Guides intervention design

### Key Methodological Strengths

- Pre-registered (transparency, reduces p-hacking)
- Large sample (N=392)
- International (though limited to West)
- Theory-driven (COM-B)
- Application-area specific analysis (nuanced)
- Mixed methods (depth + breadth)
- Validated scales
- Multiple professions included

## Connections

- [[Blease 2024 - Psychiatrists Experiences GenAI]] - Similar findings on training needs, admin burden focus
- [[Khalil 2025 - AI Competence Psychiatric Nurses]] - Complementary on training interventions
- [[Cross 2024 - AI Use Community MH Professionals Survey]] - Another large-scale attitudes survey
- Contrast with Turkish MHP studies (when available) - how do cultural, resource, regulatory contexts differ?
- Links to technology acceptance literature (TAM, UTAUT) but uses COM-B instead
- Informs training curriculum design
- Guides policy on AI integration in mental health

---
**Rating:** ⭐⭐⭐⭐⭐
**Date processed:** 2024-12-13

**Why 5 stars:**
- Most rigorous and comprehensive study of MHP AI attitudes to date
- Pre-registered with transparent methodology
- Theory-driven with actionable findings
- Application-area specific insights (not one-size-fits-all)
- Identifies MODIFIABLE factors (ethical education, affinity building)
- International sample
- Directly applicable to Turkish context (training needs, ethical focus, profession differences)
- Mixed methods provides depth + breadth
- Critical for my research: identifies what to measure, what predicts adoption, how to design interventions
